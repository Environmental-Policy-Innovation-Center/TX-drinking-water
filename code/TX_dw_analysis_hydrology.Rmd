---
title: "TX Drinking Water Data Analysis - Hydrology"
author: "EmmaLi Tsai"
date: "2024-02-23"
output: html_document
---
## Loading packages 
```{r}
library(tidyverse)
library(leaflet)
library(sf)
library(aws.s3)
library(googledrive)
```

## Loading data lists 
```{r}
# reading demographic, environmental (gw and sw), water delivery system (wds)
# and financial lists generated in TX_dw_collating: 
demo <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_demographic_list.RData")
enviro_sw <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_enviro_surface_list.RData")
enviro_gw <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_enviro_ground_list.RData")
wds <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_water_delivery_list.RData")
fin <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_financial_list.RData")

keys <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_merging_keys_list.RData")

crosswalk <- aws.s3::s3read_using(read.csv, 
                                  object = "s3://tech-team-data/pws_crosswalk/pws_census_tract_weighted_crosswalk.csv")%>%
  # if the geoid is missing prefix 0, add it back in
  mutate(tract_geoid = as.character(tract_geoid),
         tract_geoid = case_when(
           str_length(tract_geoid) == 10 ~ paste0(0, tract_geoid),
           TRUE ~ tract_geoid
         )) %>%
  # some tract geoids in the crosswalk are NAs - assuming these are errors 
  filter(!(is.na(tract_geoid)))
```

## Does the system have adequate water supply?
```{r}
# NOTE - there MIGHT be some pwsid & names we can link together based on 
# entity names, but would require some fuzzy name matching (again)

# comprehensive report here: https://www.twdb.texas.gov/waterplanning/swp/2022/docs/SWP22-Water-For-Texas.pdf?d=126542.70000004768
# TODO: this report also has annual groundwater availability by aquifer ??!!
# would be cool to match this with our aquifer data to identify counties that 
# might be at risk. And they also have socioeconomic impact (pg 180)?!?!??!

# projected values to 2070 - values are in acre-feet/year
proj_pop <- wds$TXSWP_pop
proj_dem <- wds$TXSWP_demands
proj_supp <- wds$TXSWP_supp
# needs also = potential shortages
proj_needs <- wds$TXSWP_needs
# not entirely sure how to incorporate strategies just yet 
proj_strat <- wds$TXSWP_strat

# checking out projected population change for each county: 
pop <- proj_pop %>%
  select(wug_county, wug_type, p2020:p2070) %>% 
  filter(wug_type == "MUNICIPAL") %>%
  group_by(wug_county) %>%
  summarize(p2020 = sum(p2020),
            p2030 = sum(p2030), 
            p2040 = sum(p2040), 
            p2050 = sum(p2050), 
            p2060 = sum(p2060), 
            p2070 = sum(p2070)) %>%
  mutate(pop_change = p2070 - p2020)
# gotta map this - grabbing census county geographies
census <- tidycensus::get_acs(
  geography = "county", 
  variables = c(total_pop = "B01003_001"), 
  state = c("TX"), 
  year = 2021,
  geometry = TRUE
)
# adding counties: 
census_tidy <- census
counties <- unlist(strsplit(census_tidy$NAME, split = ","))
census_tidy$counties <- trimws(counties[grepl("County", counties)])
counties <- census_tidy %>% 
  group_by(counties) %>% 
  mutate(county_geo = st_union(geometry)) %>%
  select(counties) %>%
  mutate(counties = toupper(counties), 
         counties = gsub(" COUNTY", "", counties)) %>%
  rename(wug_county = counties)

# combining with pop trends: 
pop_sf <- pop %>%
  left_join(counties) %>%
  st_as_sf() %>%
  st_transform(., st_crs(census))

# plotting to see projected population change by county: 
pop_pal <- colorBin(
  palette = viridis::viridis(10),
  bins = c(0, 100, 500, 1000, 50000, 100000, 500000, 1000000, 1564476))

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels,
                   group = "Toner Lite") %>%
  addPolygons(data = pop_sf,
              opacity = 9,
              color = ~pop_pal(pop_change),
              weight = 1,
              label = paste0("county: ", pop_sf$wug_county,
                "; pop change: ", pop_sf$pop_change)) %>%
  addLegend("bottomright",
            pal = pop_pal,
            values = c(0, 100, 500, 1000, 50000, 100000, 500000, 1000000, 1564476),
            title = "pop change",
            opacity = 1)

# Combining demand, supplies, and needs stats 
dem <- proj_dem %>%
  select(wug_county, entity_name, wug_type, d2020:d2070) %>%
  pivot_longer(d2020:d2070) %>%
  mutate(name = gsub("d", "", name)) %>%
  rename(decade = name, 
         demands = value)

sup <- proj_supp %>%
  select(wug_county, entity_name, wug_type, ws2020:ws2070) %>%
  pivot_longer(ws2020:ws2070) %>%
  mutate(name = gsub("ws", "", name)) %>%
  rename(decade = name, 
         supplies = value)

needs <- proj_needs %>%
  select(wug_county, entity_name, wug_type, n2020:n2070) %>%
  pivot_longer(n2020:n2070) %>%
  mutate(name = gsub("n", "", name)) %>%
  rename(decade = name, 
         needs = value)

# grabbing summaries to understand demand, supplies, and projected needs: 
dem_summ <- dem %>%
  group_by(wug_type, decade) %>%
  summarize(sum_dem = sum(demands))
sup_summ <- sup %>%
  group_by(wug_type, decade) %>%
  summarize(sum_sup = sum(supplies))
needs_summ <- needs %>%
  group_by(wug_type, decade) %>%
  summarize(sum_need = sum(needs))

swp <- merge(dem_summ, sup_summ)
swp <- merge(swp, needs_summ)
swp_long <- swp %>%
  pivot_longer(sum_dem:sum_need)

ggplot(swp_long, aes(x = decade, y = value, group = name, 
                       color = name)) + 
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_wrap(~wug_type) + 
  theme_minimal() 


# what does the distribution of needs look like across counties? 
needs_plot <- ggplot(needs, aes(x = decade, y = needs, 
                                color = wug_county)) + 
  geom_point() + 
  facet_wrap(~wug_type, scales = "free") + 
  theme_minimal() + 
  theme(legend.position = "none")
plotly::ggplotly(needs_plot)

# what do municipal needs look like spatially?
county_needs <- needs %>%
  filter(wug_type == "MUNICIPAL") %>%
  group_by(wug_county, decade) %>%
  summarize(mean_needs = mean(needs)) %>%
  pivot_wider(names_from = decade, values_from = mean_needs) %>%
  mutate(net_needs = `2070` - `2020`) %>%
  select(wug_county, net_needs) %>%
  left_join(counties) %>%
  st_as_sf() %>%
  st_transform(., crs = st_crs(census))

# plotting to see projected population change by county: 
needs_pal <- colorNumeric(
  palette = viridis::viridis(8),
  domain = county_needs$net_needs)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels,
                   group = "Toner Lite") %>%
  addPolygons(data = county_needs,
              opacity = 9,
              color = ~needs_pal(net_needs),
              weight = 1,
              label = paste0("county: ", county_needs$wug_county,
                "; net needs: ", round(county_needs$net_needs, 2))) %>%
  addLegend("bottomright",
            pal = needs_pal,
            values = county_needs$net_needs,
            title = "Net Needs",
            opacity = 1)

# Overall findings: 
#   - Out of all six possible water use types, municipal has the largest
#     increase in projected needs from 2020 - 2070. The county with the 
#     largest overall municipal water needs is Harris (i.e., Houston), 
#     followed by Tarrant and Dallas (both in Dallas-Fort Worth area). 
# 
#   - When mapping net needs (needs in 2070 - needs 2020), the county with the 
#     largest net increase is Potter county, located near Amarillo. High net 
#     needs are mostly found around cities. 
# 
#   - Largest projected population increases are mostly near cities 
#     which is expected. Harris, Collin, and Montgomery have the largest 
#     projected population increases. 
# 
#   - for both irrigation and municipal water categories, the demand 
#     largely outweighs water supplies (aside from 2020 in the municipal 
#     category)

# notes from sync with Charles: 
# not as important for E TX deliverable but state-wide analysis 
# mine to 2050 
# demand calculations are not always easy due to tech advancements - take 
# it with a grain of salt 
# we can't assume boundaries with aquifers - but we don't really have a choice 
# https://iopscience.iop.org/article/10.1088/1748-9326/ab0db7/meta
```

## Has the system reported any water quality violations?
```{r}
# grabbing sdiws violations by pwsid: 
viols <- keys$analysis_keys

# creating a quick graph to investigate results: 
viol_long <- viols %>%
  as.data.frame() %>%
  select(-geometry) %>%
  pivot_longer(paperwork_violations_10yr:total_violations_5yr)

# violation stats: 
viol_long %>%
  group_by(name) %>%
  filter(value > 0) %>% 
  summarize(total = length(unique(pwsid)))

# checking out trends with healthbased viols over the past 5 years and 
# relationship to % POC and MHI
ggplot(viols, aes(x = estimate_poc_alone_per, y = estimate_mhi)) + 
  geom_point() +
  geom_point(data = viols %>% filter(healthbased_violations_5yr > 0), 
             color = "red")

# grabbing stats for 5yr health-based violation bins: 
viols %>%
    as.data.frame() %>%
    select(-geometry) %>%
    mutate(viol_bin = cut(healthbased_violations_5yr, 7)) %>%
    group_by(viol_bin) %>%
    summarize(total_utilities = n(),
              mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_poc = mean(estimate_poc_alone_per, na.rm = T))

# by deciles(ish), had to break them up into more bins
viols %>%
  as.data.frame() %>%
  select(-geometry) %>%
  mutate(viol_bin = cut(healthbased_violations_5yr, 
                       breaks = c(unique(quantile(healthbased_violations_5yr, 
                                           probs = seq(0, 1, by = 0.01), 
                                           na.rm = TRUE))), 
                       include.lowest = TRUE)) %>%
  group_by(viol_bin) %>%
    summarize(total_utilities = n(),
              mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_poc = mean(estimate_poc_alone_per, na.rm = T)) 
  # mutate(quantile = c("0-20","20-40","40-60","60-80","80-100", "NA"))

# what about all of the other categories of violations? 
ggplot(viol_long, aes(x = estimate_poc_alone_per, y = value, color = name)) +
  geom_point() +
  facet_wrap(~name, scales = "free") +
  theme_bw() +
  theme(legend.position = "none") +
  labs(x = "% POC", y = "Number of Violations") +
  ggtitle("SDWIS Violations By % POC")

ggplot(viol_long, aes(x = estimate_mhi, y = value, color = name)) +
  geom_point() +
  facet_wrap(~name, scales = "free") +
  theme_bw() +
  labs(x = "MHI", y = "Number of Violations") +
  ggtitle("SDWIS Violations By Median Household Income")


# Quick Summary: 
# 4542 pwsids in total 
#   - 703 have had health-based violations over past 5 years (15.48%)
#   - 1201 have had health-based violations over past 10 years (26.44%)
#   
#   - 2673 have had paperwork violations over the past 5 years (58.85)
#   - 3637 have had paperwork violations over the past 10 years (80.07%)
# 
#   Qualitatively, if your mHI is < 100,000 and % POC is < 30%, you're more
#   likely to have more health-based violations over the past 5 years. 
# 
#   When looking at bins of health-based violations over the past 5 years, 
#   most utilities (4484) have less than 25 violations. As the number of 
#   violation increase the MHI decreases. % POC is highest at low levels of 
#   health-based violations, but that might be because the total number of
#   utilities that fall within this category is higher. 

# After splitting the data into more equal bins (deciles): 
# MHI appears to decrease as quantile increases, and % poc decreases
```

## How many boil water notices have there been over the past five years?
```{r}
# don't have this data yet - need to be FOIA'd
```

## Have there been any enforcement actions?
```{r}
# this doesn't really have the information that I need, so I created another 
# function 
# TODO: add this enforcement action function to the R package: 
sdwis <- wds$sdwis

# grabbing the raw enforcement actions from SDWIS, which should be 
# fully updated: 
source("./code/functions/get_SDWIS_enforcement.R")
sdwis_enf <- get_SDWIS_enforcement(pwsid = demo$census$pwsid)

# summarizing data by five and ten years: 
enf_summary_5yr <- sdwis_enf %>%
  filter(enf_year >= year(Sys.Date())-5) %>%
  group_by(pwsid) %>%
  summarize(enf_5yr = length(unique(enforcement_id))) 

enf_summary_10yr <- sdwis_enf %>%
  filter(enf_year >= year(Sys.Date())-10) %>%
  group_by(pwsid) %>%
  summarize(enf_10yr = length(unique(enforcement_id))) 

enf_summary <- merge(enf_summary_10yr, enf_summary_5yr, by = "pwsid", 
                     all.x = T) %>%
  mutate(enf_5yr = replace_na(enf_5yr, 0))

# combining with the rest of the pwsids that don't have any 
# enforcement actions: 
sdwis_enf_all <- merge(enf_summary, keys$analysis_keys, by = "pwsid", 
                       all.y = T) %>%
  mutate(enf_5yr = replace_na(enf_5yr, 0), 
         enf_10yr = replace_na(enf_10yr, 0))

summary(sdwis_enf_all)

# what percentage of pwsids have an enforcement action over the past 5yrs? 
sdwis_enf_all %>%
  filter(enf_10yr > 0) %>%
  count()

# plotting enforcement actions by violation type: 
enf_viol_summary <- sdwis_enf_all %>%
  pivot_longer(paperwork_violations_10yr:total_violations_5yr)

ggplot(enf_viol_summary, aes(x = enf_5yr, 
                          y = value, 
                          color = estimate_mhi)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  facet_wrap(~name, scales = "free") + 
  theme_minimal() +
  labs(x = "Enforcement Actions, 5yr", y = "Violation Type")

# checking out just health-based violations in relation to POC and MHI:
ggplot(sdwis_enf_all, aes(x = enf_5yr, 
                          y = healthbased_violations_5yr, 
                          color = estimate_mhi)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  theme_minimal() +
  labs(x = "Enforcement Actions, 5yr", y = "Health-based Violations, 5yr")

ggplot(sdwis_enf_all, aes(x = enf_5yr, 
                          y = healthbased_violations_5yr, 
                          color = estimate_poc_alone_per)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  theme_minimal() +
  labs(x = "Enforcement Actions, 5yr", y = "Health-based Violations, 5yr")

# checking this out as a table: 
sdwis_enf_all %>%
    as.data.frame() %>%
    select(-geometry) %>%
    mutate(enf_bin = cut(enf_5yr, 8)) %>%
    group_by(enf_bin) %>%
    summarize(total_utilities = n(),
              mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_poc = mean(estimate_poc_alone_per, na.rm = T))

# by quantiles:
sdwis_enf_all %>%
  as.data.frame() %>%
  select(-geometry) %>%
  mutate(enf_bin = cut(enf_5yr, 
                       breaks = c(unique(quantile(enf_5yr, 
                                                  probs = seq(0, 1, by = 0.05), 
                                                  na.rm = TRUE))), 
                       include.lowest = TRUE)) %>%
  group_by(enf_bin) %>%
  summarize(total_utilities = n(),
            paperwork_10yr = mean(paperwork_violations_10yr), 
            paperwork_5yr = mean(paperwork_violations_5yr), 
            health_10yr = mean(healthbased_violations_10yr), 
            health_5yr = mean(healthbased_violations_5yr), 
            mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_poc = mean(estimate_poc_alone_per, na.rm = T))
  # mutate(quantile = c("0-20","20-40","40-60","60-80","80-100", "NA"))

# Overall findings: 
# - 2928 (64.46%) of pwsids have had an enforcement action over the past 
#   5 years, and 3930 (86.53%) over the past 10 years. 
# 
# - mean enforcement actions over the past 10 years: 42.6, and 20.7 over 
#   the past 5 years. However, these data are highly skewed. 
# 
# - to no surprise, more health-based violations also indicate more 
#   enforcement actions, but there's alone line that appears where there 
#   are more enforcement actions but no health-based violations (possible these 
#   violations are paperwork instead)
# 
# - there is a strong linear relationship between the number of enforcement 
#   actions and the number of total violations over the past 5 and 10 years. 
# 
# - Visually it appears that paperwork violations (in comparison to health based) 
#   often result in a enforcement action
# 
# - utilities with low enforcement actions over the last 5 years have a 
#   higher MHI and %POC

```

## What is the Climate Vulerability Index?
```{r}
# loading cvi: 
cvi <- demo$cvi 
cvi_tidy <- cvi %>%
  select(-X) %>%
  rename(census_tract = fips_code)

# loading analysis keys: 
analysis_keys <- keys$analysis_keys

# loading tract crosswalk: 
pwsids <- unique(demo$census$pwsid)
tx_crosswalk <- crosswalk %>%
  select(-X) %>%
  filter(pwsid %in% pwsids)

# merging cvi with the crosswalk: 
cvi_cross <- merge(cvi_tidy, tx_crosswalk, by.x = "census_tract", 
      by.y = "tract_geoid") %>%
  mutate(cvi_weighted  = overall_cvi_score*tract_parcel_weight) 

cvi_weighted <- cvi_cross %>%
  group_by(pwsid) %>%
  summarize(cvi_weighted_score = weighted.mean(cvi_weighted))

# what's the mean cvi for utilities?
mean(cvi_weighted$cvi_weighted_score)
median(cvi_weighted$cvi_weighted_score)

# adding geographies for mapping: 
pwsid_geometries <- demo$census %>%
  select(pwsid, geometry)

cvi_weighted_geoms <- merge(cvi_weighted, pwsid_geometries) %>%
  st_as_sf(.) %>%
  st_transform(., crs = st_crs(enviro_sw$major_river_basins))

cvi_pal <- colorNumeric(
  palette = viridis::mako(9),
  domain = cvi_weighted_geoms$cvi_weighted_score)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels, group = "Toner Lite") %>%
  addPolygons(data = cvi_weighted_geoms,
              opacity = 9,
              color = ~cvi_pal(cvi_weighted_score),
              weight = 1,
              label = paste0("pwsid: ", cvi_weighted_geoms$pwsid,
                "; cvi: ", round(cvi_weighted_geoms$cvi_weighted_score, 2))) %>%
  addLegend("bottomright",
            pal = cvi_pal,
            values = cvi_weighted_geoms$cvi_weighted_score,
            title = "cvi",
            opacity = 1)

# how does systems with high CVI relate to %POC, MHI, and violations?
# assuming strongly correlated with %POC and MHI, since I think these are 
# variables incorporated into the CVI calculation. 
cvi_analysis <- cvi_weighted %>%
  left_join(analysis_keys)

ggplot(cvi_analysis, aes(x = cvi_weighted_score, 
                          y = estimate_mhi)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  theme_minimal() +
  geom_point(data = cvi_analysis %>% 
               filter(healthbased_violations_5yr>0), 
             color = "red") +
  geom_smooth(data = cvi_analysis %>% 
                filter(healthbased_violations_5yr>0), 
             color = "red") + 
  labs(x = "CVI", y = "MHI")

ggplot(cvi_analysis, aes(x = cvi_weighted_score, 
                          y = estimate_poc_alone_per)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  theme_minimal() +
  geom_point(data = cvi_analysis %>% 
               filter(healthbased_violations_5yr>0), 
             color = "red") +
  geom_smooth(data = cvi_analysis %>% 
                filter(healthbased_violations_5yr>0), 
             color = "red") + 
  labs(x = "CVI", y = "%POC")


# checking out binned results in table form: 
cvi_analysis %>%
    as.data.frame() %>%
    select(-geometry) %>%
    mutate(cvi_bin = cut(cvi_weighted_score, 5)) %>%
    group_by(cvi_bin) %>%
    summarize(total_utilities = n(),
              paperwork_10yr = mean(paperwork_violations_10yr), 
              paperwork_5yr = mean(paperwork_violations_5yr), 
              health_10yr = mean(healthbased_violations_10yr), 
              health_5yr = mean(healthbased_violations_5yr)) 

# by quantile: 
cvi_analysis %>%
  as.data.frame() %>%
  select(-geometry) %>%
  mutate(cvi_bin = cut(cvi_weighted_score, 
                       breaks = c(quantile(cvi_weighted_score, 
                                           probs = seq(0, 1, by = 0.20), 
                                           na.rm = TRUE)), 
                       include.lowest = TRUE)) %>%
  group_by(cvi_bin) %>%
  summarize(total_utilities = n(),
            paperwork_10yr = mean(paperwork_violations_10yr), 
            paperwork_5yr = mean(paperwork_violations_5yr), 
            health_10yr = mean(healthbased_violations_10yr), 
            health_5yr = mean(healthbased_violations_5yr), 
            mean_mhi = mean(estimate_mhi, na.rm = T), 
            mean_poc = mean(estimate_poc_alone_per, na.rm = T)) %>%
  mutate(quantile = c("0-20","20-40","40-60","60-80","80-100"))

# Overall findings: 
# - Spatially, CVI is high within cities, decreases in suburban areas, and 
#   increases in rural systems 

# - Most systems (823) fall within CVI values between 0.263-0.394. The mean
#   CVI is 0.31, and the median is 0.32.

# - As CVI increases, mean health-based violations over the past 5 and 10 years
#   increases. 

# - paperwork violations over the past 5 years are higher at utilities with low
#   CVI (which is the opposite of health-based violations).

# - CVI doesn't appear to be tightly related to %POC, but CVI increases with 
#   as MHI decreases

# By quantile: 
#  - Utilities that fall under the highest CVI quantile (0.47 - 0.66), have 
#   lowest MHI, largest health-based violations over the past 5 and 10 years, 
#   and the lowest number of paperwork violations over the past 10 years
```

## Does the system use green energy/focus on green energy?
```{r}
# We can actually probably answer this using the IUPs GPR
iup <- fin$TX_PPL_SFY14_24 %>%
  rename(pwsid = pws_id)

```

## How much water loss does the system have?
```{r}
# real loss GMD = gallons/mile/day 
# GCD = gallons/connection/day 
# ILI = Infrastructure leakage index 
# GPCD = gallons per capita per day 
# this is NOT a comprehensive list - I believe it's just for utilities 
# with more than 3,300 connections 
# 
# apparent loss = paper losses when water reaches a customer but the volume 
#   is not accurately measured due to meter inaccuracy 
# real loss = physical loss from infrastrucutre leakage - occur prior to 
#   reaching the customer (we care more about these, right?!)
all_wl <- wds$water_loss

# water loss audits just have system name - need to prep the data for string 
# matching: 
pwsid_keys <- demo$census %>%
  select(pwsid, pws_name) %>%
  mutate(pws_name_tidy = str_to_upper(pws_name), 
         pws_name_tidy = str_squish(pws_name_tidy), 
          # remove hyphens 
         pws_name_tidy = gsub("-", "", pws_name_tidy), 
         # remove all spaces 
         pws_name_tidy = gsub(" ", "", pws_name_tidy), 
         # remove #
         pws_name_tidy = gsub("#", "", pws_name_tidy)) %>%
  unique() %>%
  select(-pws_name)

# grabbing water loss audit data: 
wl <- wds$water_loss %>%
  janitor::clean_names() %>%
  select(year, name_of_utility, real_loss_cost_in_dollars, 
         apparent_loss_cost_in_dollars) %>%
  mutate(name_of_utility_tidy = str_to_upper(name_of_utility), 
         name_of_utility_tidy = str_squish(name_of_utility_tidy), 
           # remove hyphens 
         name_of_utility_tidy = gsub("-", "", name_of_utility_tidy), 
         # remove all spaces 
         name_of_utility_tidy = gsub(" ", "", name_of_utility_tidy), 
         # remove #
         name_of_utility_tidy = gsub("#", "", name_of_utility_tidy))

# matching names and pwsids: 
wl_pwsids <- merge(wl, pwsid_keys,
                   by.x = "name_of_utility_tidy", by.y = "pws_name_tidy", 
                   all.x = TRUE)
# 2,773 water systems 
  
# how many don't have a name match? 200
missing_pwsid <- wl_pwsids %>%
  filter(is.na(pwsid)) %>%
  select(name_of_utility_tidy) %>%
  unique()

# pulling name matches from a webscrape: https://dww2.tceq.texas.gov/DWW/JSP/SearchDispatch?number=&name=&ActivityStatusCD=All&county=All&WaterSystemType=All&SourceWaterType=All&SampleType=null&begin_date=2%2F8%2F2022&end_date=2%2F8%2F2024&action=Search+For+Water+Systems
URL <- "https://docs.google.com/spreadsheets/d/1Ds2GeJ8AMWqhBKRcIAXgO0Po8c9l_syVz4JFkeCNyXk/edit#gid=0"
dl <- googledrive::drive_download(
  as_id(URL),
  path = 'temp1.xlsx', 
  type = "xlsx")
pwsid_names <- readxl::read_excel('temp1.xlsx', col_names = TRUE) %>%
  janitor::clean_names() %>%
  mutate(water_system_name = str_to_upper(water_system_name), 
         water_system_name = str_squish(water_system_name)) 
file.remove("temp1.xlsx")

# removing fact sheet summary string and tidying before name merge: 
pwsid_names$utility_name_tidy <- unlist(strsplit(pwsid_names$water_system_name, " FACT SHEET SUMMARY SHEET"))
pwsid_names_tidy <- pwsid_names %>% select(water_system_no, utility_name_tidy) %>%
  rename(pwsid = water_system_no) %>%
  # remove hyphens 
  mutate(utility_name_tidy = gsub("-", "", utility_name_tidy), 
         # remove all spaces 
         utility_name_tidy = gsub(" ", "", utility_name_tidy), 
         # remove #
         utility_name_tidy = gsub("#", "", utility_name_tidy))
       
match_names <- merge(missing_pwsid, pwsid_names_tidy, by.x = "name_of_utility_tidy", 
      by.y = "utility_name_tidy", all.x = TRUE) %>%
  filter(!is.na(pwsid))

# recombining: 
all_pwsid_names <- merge(wl_pwsids, match_names, by = "name_of_utility_tidy", all.x = TRUE) %>%
  mutate(pwsid = case_when(
    is.na(pwsid.x) ~ pwsid.y, 
    is.na(pwsid.y) ~ pwsid.x, 
    TRUE ~ "no match"
  )) %>%
  select(-c(pwsid.x, pwsid.y))

# there are still 115 pwsids missing: 
all_pwsid_names %>%
  filter(is.na(pwsid)) %>%
  distinct(name_of_utility_tidy)

# pulling in TCEQ historical names for help: 
hist_names <- aws.s3::s3read_using(read.csv, 
                                  object = "s3://tech-team-data/state-drinking-water/TX/raw/TX_TCEQ_DWW/TX_20231217/WaterSystemDetail/TX_Water System Historical Names_20231217_20231229203427.csv")

hist_names_p2 <- 
  aws.s3::s3read_using(read.csv, 
                                  object = "s3://tech-team-data/state-drinking-water/TX/raw/TX_TCEQ_DWW/TX_20231203/WaterSystemDetail/TX_Water System Historical Names_20231203.csv")

all_hist_names <- rbind(hist_names, hist_names_p2) %>%
  janitor::clean_names() %>%
  # remove hyphens 
  mutate(historical_name_s = gsub("-", "", historical_name_s), 
         # remove all spaces 
         historical_name_s = gsub(" ", "", historical_name_s), 
         # remove #
         historical_name_s = gsub("#", "", historical_name_s))

# YEEHAW!!!
all_name_matches <- merge(all_pwsid_names, all_hist_names, 
                          by.x = "name_of_utility_tidy", 
                          by.y = "historical_name_s", all.x = TRUE) %>%
  mutate(final_pwsid = paste0(pwsid, water_system_no), 
         final_pwsid = gsub("NA", "", final_pwsid)) %>%
  # catching instances where the name matched with both datasets: 
  mutate(final_pwsid = 
           case_when(
             pwsid == water_system_no ~ pwsid, 
             TRUE ~ final_pwsid
           )) %>%
  # fixing matches where the pwsids are NOT identical - did this through 
  # some google searches: 
  mutate(final_pwsid = case_when(
    # the Arrowhead water system in Hill county is different from this one: 
    name_of_utility == "Arrowhead Water System" ~ pwsid, 
    name_of_utility == "Bolivar WSC" ~ pwsid, 
    name_of_utility == "CITY OF ARCOLA" ~ pwsid, 
    # different from the Morgans Point Resort
    name_of_utility == "CITY OF MORGANS POINT" ~ pwsid, 
    name_of_utility == "ELM RIDGE WCID" ~ pwsid, 
    name_of_utility == "Green Acres Mobile Home Park" ~ pwsid, 
    name_of_utility == "Harris County MUD 49" ~ pwsid, 
    name_of_utility == "Pleasant Hill WSC" ~ pwsid, 
    name_of_utility == "Woodland Oaks Subdivision" ~ pwsid, 
    name_of_utility %in% c("THE COMMONS WATER SUPPLY INC", 
                           "The Commons Water Supply Inc") ~ water_system_no, 
    # these below just didn't match but easy to do by hand: 
    name_of_utility == "CITY OF MCALLEN" ~ "TX1080006",
    name_of_utility %in% c("Fort Bend Co MUD # 42 Water Plant", 
                           "FORT BEND COUNTY MUD 42") ~ "TX0790254",
    TRUE ~ final_pwsid))

# NOTE: there are three: 
# - HARRIS COUNTY UTILITY DISTRICT 14 and 15 
# - LCRA WEST TRAVIS COUNTY REGIONAL WS 
# that can't be matched 

# tidying and analysis: 
wl_tidy <- all_name_matches %>%
  select(year, name_of_utility, real_loss_cost_in_dollars, 
         apparent_loss_cost_in_dollars, final_pwsid) %>%
  rename(pwsid = final_pwsid, 
         real_loss = real_loss_cost_in_dollars, 
         appar_loss = apparent_loss_cost_in_dollars) %>%
  mutate(real_loss = readr::parse_number(real_loss), 
         appar_loss = readr::parse_number(appar_loss)) %>%
  left_join(analysis_keys) %>%
  st_as_sf() %>%
  st_transform(., crs = st_crs(census))

# summary stats: 
wl_summary <- wl_tidy %>%
  group_by(pwsid) %>%
  summarize(mean_real_loss = mean(real_loss), 
            mean_appar_loss = mean(appar_loss), 
            mean_poc = mean(estimate_poc_alone_per), 
            mean_mhi = mean(estimate_mhi), 
            mean_health_5yr = mean(healthbased_violations_5yr))

# plotting relationships: 
ggplot(wl_tidy, aes(x = real_loss)) + 
  geom_histogram()

ggplot(wl_summary, aes(x = mean_mhi, y = mean_real_loss)) + 
  geom_point(aes(color = mean_poc)) + 
  geom_point(data = wl_summary %>%
               filter(mean_health_5yr > 0), color = "red")

ggplot(wl_summary, aes(x = mean_poc, y = mean_real_loss)) + 
  geom_point(aes(color = mean_mhi)) + 
  geom_point(data = wl_summary %>%
               filter(mean_health_5yr > 0), color = "red")

ggplot(wl_summary, aes(x = mean_appar_loss, y = mean_real_loss)) + 
  geom_point() + 
  geom_point(data = wl_summary %>%
               filter(mean_health_5yr > 0), color = "red")

# table of status for each apparent loss bin: 
wl_summary %>%
  as.data.frame() %>%
  select(-geometry) %>%
  mutate(real_loss_bin = cut(mean_real_loss, 
                             breaks = c(quantile(mean_real_loss, 
                                                 probs = seq(0, 1, by = 0.20))), 
                             include.lowest = TRUE)) %>%
  group_by(real_loss_bin) %>%
  summarize(total_utilities = n(),
            mean_poc = mean(mean_poc, na.rm = T), 
            mean_mhi = mean(mean_mhi, na.rm = T), 
            mean_health_5yr = mean(mean_health_5yr, na.rm = T)) %>%
  mutate(quantile = c("0-20","20-40","40-60","60-80","80-100"))

# what does high real loss look like spatially?
wl_summary_sf <- wl_summary %>%
  st_as_sf() %>%
  st_transform(., crs = st_crs(census))

loss_pal <- colorNumeric(
  palette = viridis::mako(9),
  domain = wl_summary_sf$mean_real_loss)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels, group = "Toner Lite") %>%
  addPolygons(data = wl_summary_sf$geometry,
              opacity = 9,
              color = ~loss_pal(mean_real_loss),
              weight = 1,
              label = paste0("pwsid: ",
                             wl_summary_sf$pwsid,
                "; real loss: ", round(wl_summary_sf$mean_real_loss, 2))) %>%
  addLegend("bottomright",
            pal = loss_pal,
            values = wl_summary_sf$mean_real_loss,
            title = "real loss",
            opacity = 1)

# TODO: what has the net change been in mean loss? this would require the min
#   and max year for each utility, since our temporal coverage varies for 
#   each. 


# Overall findings: 
# - mean real loss is $997,000,000; median is $19,050 - so LOTs of skew 
# - mean apparent loss is $845,700,000; median is $10,010
# - visually, highest mean real loss is around mhi OF ~$75,000, and 
#   %POC of ~30%
# - At higher quantiles, % POC increases, but the trend with MHI and mean 
#   health-based viols over the past 5 years is less clear. MHI is largest 
#   at the 80-100% quantile, but also high at the 0-20% quantile. For health
#   based violations over the past 5-years, highest is at 0-20 quantile 
#   and 40-60%
```

## What type of treatment is in use? 
```{r}
# statewide basis - people pulling from sw are using different treatment 
# techniques than groundwater 
# however - there is likely going to be minimal difference 
#         - chlorine and fluoride and mechanical (membrane)
# double-check 
# filter by counties - the categories would get dropped down to 5 and then 
# determine if it's realisitc or not 

treatments_dec17 <- aws.s3::s3read_using(read.csv, 
                           object = "state-drinking-water/TX/raw/TX_TCEQ_DWW/TX_20231217/WaterSystemFacilities/TX_Treatment Plant Unit Process Flows_20231217_20231229203427.csv",
                           bucket = "tech-team-data") %>%
  clean_names()

treatments_dec03 <- aws.s3::s3read_using(read.csv, 
                           object = "state-drinking-water/TX/raw/TX_TCEQ_DWW/TX_20231203/WaterSystemFacilities/TX_Treatment Plant Unit Process Flows_20231203.csv",
                           bucket = "tech-team-data") %>%
  clean_names()

# this is probably not a comprehensive list 
all_treat <- rbind(treatments_dec03, treatments_dec17)
treat_simple <- all_treat %>%
  filter(water_system_no %in% demo$census$pwsid) %>%
  group_by(water_system_no) %>%
  distinct(supply)

# grabbing the total number of treatment steps: 
treat_steps <- treat_simple %>%
  group_by(water_system_no) %>%
  summarize(treat_steps = n())

ggplot(treat_steps, aes(x = n)) + 
  geom_histogram() + 
  labs(x = "Number of Treatment Steps", y = "Count of PWSIDs")+ 
  theme_minimal()

# combining treatment steps with other information we know about the pwsid: 
pwsid_info <- demo$census
pwsid_info <- pwsid_info %>%
  select(pwsid:primary_source_code)

pwsid_treat <- merge(treat_steps, pwsid_info, 
                     by.x = "water_system_no", by.y = "pwsid",
                     all.y = TRUE) 

ggplot(pwsid_treat, aes(x = treat_steps, color = primary_source_code, 
                        fill = primary_source_code)) + 
  geom_histogram() + 
  facet_wrap(~primary_source_code, scales = "free") + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  labs(x = "Number of Treatment Steps", y = "Number of PWSIDs")

# what's the summary of treatment steps by source water? 
pwsid_treat %>%
  group_by(primary_source_code) %>%
  summarize(total = n(), 
            have_info = sum(!is.na(treat_steps)),
            mean_treat_steps = mean(treat_steps, na.rm = T), 
            median_treat_steps = median(treat_steps, na.rm = T)) 


# Overall findings: 
# - the coverage for these data is pretty poor - we only have data for 
#   306 pwsids out of 4542 (~6.7%). Out of these, most of them are pulling 
#   surface water (275), followed by GU (19), which is groundwater under the 
#   influence of surface water
# - for those pulling surface water, they have a mean of 25 treatment steps 
# - utilities pulling SWP has ~6 treatment steps, GU have ~5 and GW 
#   has ~4.
```

## What is the source of water? 
```{r}
# basic info from sdwis: 
source <- demo$census
water_source <- source %>%
  select(pwsid, pws_name, city_served, county_served, primary_source_code)

ggplot(water_source, aes(x = primary_source_code, fill = primary_source_code)) +
  theme_minimal() + 
  geom_histogram(stat = "count")+ 
  scale_color_discrete(name = "") + 
  scale_fill_discrete(name = "") + 
  labs(x = "Primary Water Source", y = "Count of PWSIDs")


# looking at county and groundwater keys: 
# NOTE: hatched aquifersare subcrop areas (part of an aquifer that lies or dips
# below other formations)
gw_keys <- keys$well_gw_county
county_gw <- gw_keys %>%
  group_by(county_name) %>%
  distinct(aquifer_one, aquifer_two, aquifer_three, 
           aquifer_four, aquifer_five) %>%
  mutate(county_name = toupper(county_name)) %>%
  pivot_longer(aquifer_one:aquifer_five) %>%
  group_by(county_name) %>%
  distinct(value) %>%
  filter(!is.na(value)) 

county_aquifers <- aggregate(value ~ county_name, unique(county_gw), paste, 
                             collapse = ", ")

# matching pwsid with county and then aquifer 
pwsid_gw <- water_source %>%
  filter(primary_source_code == "GW") %>%
  left_join(county_gw, c("county_served" = "county_name")) 
  # separate(value, c("aquifer", "type"), sep = "-")

pwsid_summary <- pwsid_gw %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(value) %>%
  summarize(number_of_pwsids = length(unique(pwsid)))

ggplot(pwsid_summary, aes(x = value, y = number_of_pwsids, 
                          color = value, fill = value)) + 
  geom_bar(stat = "identity") + 
  coord_flip() + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  labs(y = "Number of Utilities", x = "Aquifer")

## calculate county-level stats to investigate community
# characteristics of those served by groundwater
census_vars <- c(total_pop = "B01003_001",
                 black_alone = "B02001_003", 
                 asian_alone = "B02001_005", 
                 white_alone = "B02001_002", 
                 AIAN_alone = "B02001_004", 
                 NAPI_alone = "B02001_006", 
                 other_alone = "B02001_007", 
                 mixed_alone = "B02001_008",
                 hisp_alone = "B03003_003", 
                 mhi = "B19013_001", 
                 under_6  = "B23008_002", 
                 over_65 = "B09021_022", 
                 only_english = "B99162_002", 
                 other_lang = "B99162_003", 
                 no_school = "B15003_002", 
                 prof_degree = "B15003_024", 
                 foreign = "B99051_005", 
                 pov_level_at_above_150 = "B06012_004")
tx_county <- tidycensus::get_acs(
  geography = "county", 
  variables = census_vars, 
  state = c("TX"), 
  year = 2021,
  geometry = TRUE
)
counties <- unlist(strsplit(tx_county$NAME, split = ","))
tx_county$counties <- trimws(counties[grepl("County", counties)])

tx_wide <- pivot_wider(tx_county, 
                       names_from = c("variable"), 
                       values_from = c("estimate", "moe"))
tx_wide <- tx_wide %>%
  select(starts_with(c("estimate", "counties"))) %>%
  # leaving out columns that are totals or mhi:
  mutate_at(vars(!c("estimate_total_pop", "estimate_mhi", "counties")), 
            ~((./estimate_total_pop)*100)) %>%
  mutate(estimate_poc_alone = (100 - estimate_white_alone)) %>%
  mutate(counties = gsub(" County", "", counties), 
         counties = toupper(counties))

county_aquifer_stats <- merge(tx_wide, county_aquifers, 
                              by.x = "counties", by.y = "county_name")

aquifer_summary <- pwsid_gw %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(value) %>%
  summarise(counties = paste(unique(county_served), collapse=", "))



# investigating surface water: 
pwsid_sw <- water_source %>%
  filter(primary_source_code == "SW") %>%
  left_join(sw_intake_keys) 

# checking out impaired basins: 
imp_basin <- enviro_sw$impaired_basins
simp_basin_names <- unlist(str_split(imp_basin$basin_name, " River|Coastal|Creek"))
imp_basin$imp_basin_names <- simp_basin_names[seq(1, length(simp_basin_names), by = 2)] 

simple_basin_info <- imp_basin %>%
  select(imp_basin_names, pct_impaired)

pwsid_sw_basins <- merge(pwsid_sw, simple_basin_info, 
                         by.x = "basin_name_short", 
                         by.y = "imp_basin_names", all.x = TRUE)

# which reservoirs link to a bunch of pwsids?
by_res <- pwsid_sw_basins %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(res_name) %>%
  summarize(total = length(unique(pwsid)))

# how many pwsids are getting from basins where the percentage impaired 
# is greater than 60%?
# TODO: probably an st_intersection here? 
pwsid_sw_basins %>%
  filter(pct_impaired >= 60) %>%
  count()


pwsid_sw_basins %>%
  as.data.frame() %>%
  select(-geometry) %>%
  left_join(analysis_keys) %>%
  select(-geometry) %>%
  mutate(pct_imp = cut(pct_impaired, 
                       breaks = c(quantile(pct_impaired, 
                                           probs = seq(0, 1, by = 0.20), 
                                           na.rm = T)), 
                       include.lowest = TRUE)) %>%
  group_by(pct_imp) %>%
  summarize(total_utilities = n(),
            mean_poc = mean(estimate_poc_alone_per, na.rm = T), 
            mean_mhi = mean(estimate_mhi, na.rm = T), 
            mean_health_5yr = mean(healthbased_violations_5yr, na.rm = T),
            mean_paperwork_5yr = mean(paperwork_violations_5yr, na.rm = T)) 



# Overall findings: 
# - most pwsids are geting water from aquifers, followed by purchasing 
#   surface water. 
# - of the pwsids pulling groundwater, most are pulling from the gulf coast 
#   major aquifer, followed by the trinity and carrizo major aquifers. 
# 
# - we have surface water intake information from 286 pwsids out of 392 
#   that pull surface water 
# - 53 pwsids are pulling surface water from a basin that is >= 60% 
#   impaired 
# - 15 pwsids are pulling from Lake Travis, and 12 from the Cedar Creek 
#   reservoir, and 12 from Lake Tawakoni 
```

Potential rabbit holes of interest: 
- SDIWS violations - investigating the type of violation (i.e. MON, RPT (?), MR (monitoring and reporting), TT (treatment technique), MCL (max contaminant level), and MRDL (max residual disinfectant))
- Deeper dive into SRF green project reserve
- Linking reservoir and groundwater info with source water quality measurements 
- Are pwsids located in a highly impaired basin more likely to have water quality violations? 
