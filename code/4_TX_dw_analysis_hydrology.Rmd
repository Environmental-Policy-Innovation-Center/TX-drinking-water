---
title: "TX Drinking Water Data Analysis - Hydrology"
author: "EmmaLi Tsai"
date: "2024-02-23"
last_updated: "2024-04-03"
output: html_document
---
## Loading packages 
```{r}
library(tidyverse)
library(leaflet)
library(sf)
library(aws.s3)
library(googledrive)
# function to get enforcement actions: 
source("./code/functions/get_SDWIS_enforcement.R")
```

## Loading data lists 
```{r}
demo <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_demographic_list.RData")
enviro_sw <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_enviro_surface_list.RData")
enviro_gw <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_enviro_ground_list.RData")
wds <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_water_delivery_list.RData")
fin <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_financial_list.RData")

keys <- aws.s3::s3read_using(readRDS, 
                            object = "s3://tech-team-data/state-drinking-water/TX/clean/TX_merging_keys_list.RData")

crosswalk <- aws.s3::s3read_using(read.csv, 
                                  object = "s3://tech-team-data/pws_crosswalk/pws_census_tract_weighted_crosswalk.csv")%>%
  # if the geoid is missing prefix 0, add it back in
  mutate(tract_geoid = as.character(tract_geoid),
         tract_geoid = case_when(
           str_length(tract_geoid) == 10 ~ paste0(0, tract_geoid),
           TRUE ~ tract_geoid
         )) %>%
  filter(!(is.na(tract_geoid)))
```

# East TX flag: 
```{r}
# NOTE: since the data here required some more fiddling, I've opted to fold 
# comparisons with East TX within each code block - otherwise this chunk would 
# be full of code for matching strings/filling pwsids, etc. 
etx_pwsid <- demo$census %>%
  filter(east_tx_flag == "yes") %>%
  distinct(pwsid)
```

## Does the system have adequate water supply?
```{r}
# comprehensive report here: https://www.twdb.texas.gov/waterplanning/swp/2022/docs/SWP22-Water-For-Texas.pdf?d=126542.70000004768

# TODO: this report also has annual groundwater availability by aquifer ??!!
# would be cool to match this with our aquifer data to identify counties that 
# might be at risk. And they also have socioeconomic impact (pg 180)?!?!??!

# data from TX State Water Plan - data are in acre-feet/year
proj_pop <- wds$TXSWP_pop
proj_dem <- wds$TXSWP_demands
proj_supp <- wds$TXSWP_supp
proj_needs <- wds$TXSWP_needs
proj_strat <- wds$TXSWP_strat

# projected population change for each county & mapping: 
pop <- proj_pop %>%
  select(wug_county, wug_type, p2020:p2070) %>% 
  filter(wug_type == "MUNICIPAL") %>%
  group_by(wug_county) %>%
  summarize(p2020 = sum(p2020),
            p2030 = sum(p2030), 
            p2040 = sum(p2040), 
            p2050 = sum(p2050), 
            p2060 = sum(p2060), 
            p2070 = sum(p2070)) %>%
  mutate(pop_change = p2070 - p2020)

census <- tidycensus::get_acs(
  geography = "county", 
  variables = c(total_pop = "B01003_001"), 
  state = c("TX"), 
  year = 2020,
  geometry = TRUE
)

# adding counties: 
census_tidy <- census
counties <- unlist(strsplit(census_tidy$NAME, split = ","))
census_tidy$counties <- trimws(counties[grepl("County", counties)])
counties <- census_tidy %>% 
  group_by(counties) %>% 
  mutate(county_geo = st_union(geometry)) %>%
  select(counties) %>%
  mutate(counties = toupper(counties), 
         counties = gsub(" COUNTY", "", counties)) %>%
  rename(wug_county = counties)

# combining with pop trends: 
pop_sf <- pop %>%
  left_join(counties) %>%
  st_as_sf() %>%
  st_transform(., st_crs(census))

# plotting to see projected population change by county: 
pop_pal <- colorBin(
  palette = viridis::viridis(10),
  bins = c(0, 100, 500, 1000, 50000, 100000, 
           500000, 1000000, 1564476))

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels,
                   group = "Toner Lite") %>%
  addPolygons(data = pop_sf,
              opacity = 9,
              color = ~pop_pal(pop_change),
              weight = 1,
              label = paste0("county: ", pop_sf$wug_county,
                "; pop change: ", pop_sf$pop_change)) %>%
  addLegend("bottomright",
            pal = pop_pal,
            values = c(0, 100, 500, 1000, 50000, 100000, 
                       500000, 1000000, 1564476),
            title = "pop change",
            opacity = 1)


# checking this out for east TX:
etx <- read.csv("./data/raw/east_TX_counties.csv") %>%
  select(-X) %>%
  mutate(county_name = toupper(county_name))

pop_etx <- pop_sf %>%
  filter(wug_county %in% etx$county_name)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels,
                   group = "Toner Lite") %>%
  addPolygons(data = pop_etx,
              opacity = 9,
              color = ~pop_pal(pop_change),
              weight = 1,
              label = paste0("county: ", pop_etx$wug_county,
                "; pop change: ", pop_etx$pop_change)) %>%
  addLegend("bottomright",
            pal = pop_pal,
            values = c(0, 100, 500, 1000, 50000, 100000, 
                       500000, 1000000, 1564476),
            title = "pop change",
            opacity = 1)



# Zooming in on municipal water needs 
needs <- proj_needs %>%
  select(wug_county, entity_name, wug_type, n2020:n2070) %>%
  pivot_longer(n2020:n2070) %>%
  mutate(name = gsub("n", "", name)) %>%
  rename(decade = name, 
         needs = value)

# just looking at 2070 municipal water needs: 
county_needs <- needs %>%
  filter(wug_type == "MUNICIPAL") %>%
  filter(decade == "2070") %>% 
  group_by(wug_county) %>%
  summarize(sum_needs = sum(needs))  %>%
  left_join(counties) %>%
  st_as_sf() %>%
  st_transform(., crs = st_crs(census))

# plotting to see projected population change by county: 
needs_pal <- colorNumeric(
  palette = viridis::viridis(8),
  domain = county_needs$sum_needs)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels,
                   group = "Toner Lite") %>%
  addPolygons(data = county_needs,
              opacity = 9,
              color = ~needs_pal(sum_needs),
              weight = 1,
              label = paste0("county: ", county_needs$wug_county,
                "; net needs: ", round(county_needs$sum_needs, 2))) %>%
  addLegend("bottomright",
            pal = needs_pal,
            values = county_needs$sum_needs,
            title = "Water Needs (2070)",
            opacity = 1)

# looking at municipal water needs in the form of a bar chart:  
proj_needs <- wds$TXSWP_needs
proj_needs <- proj_needs %>%
  group_by(wug_county) %>%
  filter(wug_type == "MUNICIPAL") %>%
  summarize(sum_n2020 = sum(n2020), 
            sum_n2070 = sum(n2070)) 
proj_needs <- proj_needs[order(proj_needs$sum_n2070, decreasing = TRUE), ]
top_counties <- proj_needs[1:50,]$wug_county

ggplot(proj_needs %>% filter(wug_county %in% top_counties), 
       aes(x = reorder(wug_county, -sum_n2070), y = sum_n2070)) + 
  geom_bar(stat = "identity", fill = "lightblue") + 
  geom_bar(aes(y = sum_n2020), fill = "pink", stat = "identity") +
  coord_flip() + 
  theme_minimal() + 
  labs(y = "Municipal Water Needs (acre-feet)", x = "County")


# zooming in on East TX: 
etx_proj_needs <- wds$TXSWP_needs %>%
  group_by(wug_county) %>%
  filter(wug_type == "MUNICIPAL") %>%
  filter(wug_county %in% etx$county_name) %>%
  summarize(sum_n2020 = sum(n2020), 
            sum_n2070 = sum(n2070)) 
etx_proj_needs <- etx_proj_needs[order(etx_proj_needs$sum_n2070, decreasing = TRUE), ]
top_counties <- etx_proj_needs[1:20,]$wug_county

ggplot(etx_proj_needs %>% filter(wug_county %in% top_counties), 
       aes(x = reorder(wug_county, -sum_n2070), y = sum_n2070)) + 
  geom_bar(stat = "identity", fill = "lightblue") + 
  geom_bar(aes(y = sum_n2020), fill = "pink", stat = "identity") +
  coord_flip() + 
  theme_minimal() + 
  labs(y = "Municipal Water Needs (acre-feet)", x = "County")


# plotting to see projected water needs by county in east TX: 
etx_county_needs <- county_needs %>%
  filter(wug_county %in% etx$county_name) 
needs_pal <- colorNumeric(
  palette = viridis::viridis(8),
  domain = etx_county_needs$sum_needs)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels,
                   group = "Toner Lite") %>%
  addPolygons(data = etx_county_needs,
              opacity = 9,
              color = ~needs_pal(sum_needs),
              weight = 1,
              label = paste0("county: ", etx_county_needs$wug_county,
                "; net needs: ", round(etx_county_needs$sum_needs, 2))) %>%
  addLegend("bottomright",
            pal = needs_pal,
            values = etx_county_needs$sum_needs,
            title = "Water Needs (2070)",
            opacity = 1)

# Overall findings:: 
#   - Out of all six possible water use types, municipal has the largest
#     increase in projected needs from 2020 - 2070. The county with the 
#     largest overall municipal water needs is Harris (i.e., Houston), 
#     followed by Tarrant and Dallas (both in Dallas-Fort Worth area). 
# 
#   - When mapping net needs (needs in 2070 - needs 2020), the county with the 
#     largest net increase is Potter county, located near Amarillo. High net 
#     needs are mostly found around cities. 
# 
#   - Largest projected population increases are mostly near cities 
#     which is expected. Harris, Collin, and Montgomery have the largest 
#     projected population increases. 
# 
#   - for both irrigation and municipal water categories, the demand 
#     largely outweighs water supplies (aside from 2020 in the municipal 
#     category)

# notes from sync with Charles: 
# not as important for E TX deliverable but state-wide analysis 
# mine to 2050 
# demand calculations are not always easy due to tech advancements - take 
# it with a grain of salt 
# we can't assume boundaries with aquifers - but we don't really have a choice 
# https://iopscience.iop.org/article/10.1088/1748-9326/ab0db7/meta
```

## Has the system reported any water quality violations?
```{r}
viols <- keys$analysis_keys 
etx_viols <- viols %>%
  filter(pwsid %in% etx_pwsid$pwsid)

# creating a quick graph to investigate results: 
viol_long <- viols %>%
  as.data.frame() %>%
  select(-geometry) %>%
  pivot_longer(paperwork_violations_10yr:total_violations_5yr)

# quick stats on violation data: 
viol_long %>%
  group_by(name) %>%
  filter(value > 0) %>% 
  summarize(total = length(unique(pwsid)))

mean(viols$healthbased_violations_5yr)
median(viols$healthbased_violations_5yr)

mean(etx_viols$healthbased_violations_5yr)
median(etx_viols$healthbased_violations_5yr)
sum(etx_viols$healthbased_violations_5yr > 0)


# checking out trends with healthbased viols over the past 5 years and 
# relationship to % POC and MHI for both TX and East TX:
ggplot(viols, 
       aes(x = estimate_poc_alone_per, 
           y = estimate_mhi)) + 
  geom_point() +
  geom_point(data = viols %>% filter(healthbased_violations_5yr > 0), 
             color = "red") + 
  geom_smooth(color = "grey") + 
  theme_minimal() + 
  labs(x = "% POC", y = "MHI") 

ggplot(etx_viols, 
       aes(x = estimate_poc_alone_per, 
           y = estimate_mhi)) + 
  geom_point() +
  geom_point(data = etx_viols %>% filter(healthbased_violations_5yr > 0), 
             color = "red") + 
  geom_smooth(color = "grey") + 
  theme_minimal() + 
  labs(x = "% POC", y = "MHI") 

# grabbing stats for 5yr health-based violation bins: 
viols %>%
    as.data.frame() %>%
    # filter(east_tx_flag == "yes") %>%
    select(-geometry) %>%
    mutate(viol_bin = cut(healthbased_violations_5yr, 7)) %>%
    group_by(viol_bin) %>%
    summarize(total_utilities = n(),
              mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_poc = mean(estimate_poc_alone_per, na.rm = T))

# grabbing stats for different quantiles: 
viols %>%
  as.data.frame() %>%
  # filter(east_tx_flag == "yes") %>%
  select(-geometry) %>%
  mutate(viol_bin = cut(healthbased_violations_5yr, 
                       breaks = c(unique(quantile(healthbased_violations_5yr, 
                                           probs = seq(0, 1, by = 0.05), 
                                           na.rm = TRUE))), 
                       include.lowest = TRUE)) %>%
  group_by(viol_bin) %>%
    summarize(total_utilities = n(),
              mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_poc = mean(estimate_poc_alone_per, na.rm = T), 
              mean_healthbased_10yr = mean(healthbased_violations_10yr), 
              mean_paperwork_5yr = mean(paperwork_violations_5yr), 
              mean_paperwork_10yr = mean(paperwork_violations_10yr),
              mean_poc = mean(estimate_poc_alone_per, na.rm = T)) 


# how do violation types relate to %POC and MHI?
ggplot(viol_long, aes(x = estimate_poc_alone_per, y = value, color = name)) +
  geom_point() +
  facet_wrap(~name, scales = "free") +
  theme_bw() +
  theme(legend.position = "none") +
  labs(x = "% POC", y = "Number of Violations") +
  ggtitle("SDWIS Violations By % POC")

ggplot(viol_long, aes(x = estimate_mhi, y = value, color = name)) +
  geom_point() +
  facet_wrap(~name, scales = "free") +
  theme_bw() +
  labs(x = "MHI", y = "Number of Violations") +
  ggtitle("SDWIS Violations By Median Household Income")


# mapping health-based violations for both TX and east TX:
viol_pal <- colorBin(
  palette = c("#003049","#6b2c39", "#d62828", "#f77f00", "#fcbf49"),
  bins = c(1, 5, 10, 50, 100, 200), 
  na.color = "#c9c9bc")

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels, group = "Toner Lite") %>%
  addPolygons(data = viols,
              # data = etx_viols,
              fillOpacity = 0.9,
              # fillOpacity = 0.9,
              # stroke = TRUE,
              # color = "black",
              color = ~viol_pal(healthbased_violations_5yr),
              # fillColor = ~viol_pal(healthbased_violations_5yr),
              weight = 1,
              label = paste0("pwsid: ", viols$pwsid,
                "; cvi: ", round(viols$healthbased_violations_5yr, 2))) %>%
  addLegend("bottomright",
            pal = viol_pal,
            values = viols$healthbased_violations_5yr,
            title = "Health Viols, 5yr",
            opacity = 1)


# how many pwsids in East TX haven't had any heath-based violations?
viols %>%
  as.data.frame() %>%
  select(-geometry) %>%
  filter(east_tx_flag == "yes") %>%
  filter(healthbased_violations_5yr == 0) %>%
  summarize(total = length(unique(pwsid)), 
            mean_poc = mean(estimate_poc_alone_per, na.rm = T), 
            mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_healthbased_10yr = mean(healthbased_violations_10yr), 
              mean_paperwork_5yr = mean(paperwork_violations_5yr), 
              mean_paperwork_10yr = mean(paperwork_violations_10yr))

# how many pwsids in East TX have health-based violations?
viols %>%
  as.data.frame() %>%
  select(-geometry) %>%
  filter(east_tx_flag == "yes") %>%
  filter(healthbased_violations_5yr > 0) %>%
  summarize(total = length(unique(pwsid)), 
            mean_poc = mean(estimate_poc_alone_per, na.rm = T), 
            mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_healthbased_10yr = mean(healthbased_violations_10yr), 
              mean_paperwork_5yr = mean(paperwork_violations_5yr), 
              mean_paperwork_10yr = mean(paperwork_violations_10yr))

# are violations related to population density? 
pop_density <- demo$census %>%
  select(pwsid, pop_density) %>%
  as.data.frame() %>%
  select(-geometry)
viols_density <- viols %>%
  left_join(pop_density)

ggplot(viols_density, aes(x = pop_density, 
                          y = healthbased_violations_5yr)) + 
  geom_point() + 
  xlim(0, 100000) + 
  theme_minimal() + 
  labs(x = "Population Density")

# are 10-yr paperwork violations related to 5-yr healthbased violations?
viols <- viols %>% 
  mutate(percent_paperwork_10yr = (paperwork_violations_10yr/total_violations_10yr)*100, 
         percent_healthbased_10yr = (healthbased_violations_10yr/total_violations_10yr)*100, 
         percent_paperwork_5yr = (paperwork_violations_5yr/total_violations_5yr)*100, 
         percent_healthbased_5yr = (healthbased_violations_5yr/total_violations_5yr)*100)

ggplot(viols, aes(x = percent_paperwork_10yr, percent_healthbased_5yr)) + 
  geom_point() + 
  geom_point(data = viols %>% filter(percent_healthbased_5yr > (100 - percent_paperwork_10yr)), 
             color = "darkred") +
  theme_minimal() + 
  labs(x = "% 10yr Violations are Not Health-based", 
       y = "% 5yr Violations are Health-based")


# are there any certain groups that are over represented in violating utilities?
race_eth_summary <- demo$census %>%
  as.data.frame() %>%
  select(-geometry) %>%
  select(pwsid, estimate_white_alone_per:estimate_hh_below_pov_per)

quant_summary <- viols %>%
  as.data.frame() %>%
  filter(east_tx_flag == "yes") %>%
  select(-geometry) %>%
  left_join(race_eth_summary) %>%
  mutate(viol_bin = cut(healthbased_violations_5yr, 
                       breaks = c(unique(quantile(healthbased_violations_5yr, 
                                           probs = seq(0, 1, by = 0.05), 
                                           na.rm = TRUE))), 
                       include.lowest = TRUE)) %>%
  group_by(viol_bin) %>%
    summarize(total_utilities = n(),
              mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_poc = mean(estimate_poc_alone_per, na.rm = T), 
              mean_healthbased_10yr = mean(healthbased_violations_10yr),
              mean_paperwork_5yr = mean(paperwork_violations_5yr),
              mean_paperwork_10yr = mean(paperwork_violations_10yr),
              mean_poc = mean(estimate_poc_alone_per, na.rm = T), 
              mean_hisp = mean(estimate_hisp_alone_per, na.rm = T), 
              mean_other_lang = mean(estimate_other_lang_per, na.rm = T), 
              mean_no_school = mean(estimate_no_school_per, na.rm = T), 
              mean_bach = mean(estimate_bachelors_per, na.rm = T), 
              mean_hh_below_pov = mean(estimate_hh_below_pov_per, na.rm = T)) 


# are any of these reltionships significant? 
corr_summary <- viols %>%
  as.data.frame() %>%
  # filter(east_tx_flag == "yes") %>%
  select(-geometry) %>%
  left_join(race_eth_summary) %>% 
  rename_with(~ str_remove(., "_alone_per"), everything()) %>% 
  rename_with(~ str_remove(., "_per"), everything()) %>%
  rename_with(~ str_remove(., "estimate"), everything()) %>%
  rename_with(~ str_remove(., "_"), everything())

all_cor <- cor(corr_summary %>% 
                 select(c(mhi:hh_below_pov)), 
               use = "pairwise.complete.obs")

cor_pvals <- cor.mtest(all_cor, conf.level = 0.95)
cor_pvals$p

corrplot(all_cor, method = 'ellipse', type = 'upper', 
         p.mat = cor_pvals$p, insig = "p-value", sig.level = -1, 
         mar=c(0,0,0,0))


# what are these utilities paying for water? 
head(viols)
water_price <- fin$TX_affordability_DAC %>%
  select(pwsid, total_water, total_sewer, total_water_year, total_sewer_year) %>%
  as.data.frame() %>%
  select(-geometry)

viol_water_summary <- viols %>%
  left_join(water_price)%>%
  as.data.frame() %>%
  # filter(east_tx_flag == "yes") %>%
  select(-geometry) %>%
  filter(!is.na(total_water_year))

viol_water_summary %>%
  mutate(viol_bin = cut(healthbased_violations_5yr, 
                        # breaks = c(0, 0.01, 800),
                       breaks = c(unique(quantile(healthbased_violations_5yr,
                                           probs = seq(0, 1, by = 0.05),
                                           na.rm = TRUE))),
                       include.lowest = TRUE)) %>%
  group_by(viol_bin) %>%
    summarize(total_utilities = n(),
              mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_poc = mean(estimate_poc_alone_per, na.rm = T), 
              mean_healthbased_10yr = mean(healthbased_violations_10yr),
              mean_paperwork_5yr = mean(paperwork_violations_5yr),
              mean_paperwork_10yr = mean(paperwork_violations_10yr), 
              mean_water = mean(total_water, na.rm = T), 
              mean_sewer = mean(total_sewer, na.rm = T), 
              mean_total_water_year = mean(total_water_year, na.rm = T), 
              mean_total_sewer_year = mean(total_sewer_year, na.rm = T)) 

ggplot(viol_water_summary, aes(x = healthbased_violations_5yr, 
                               y = total_water_year + total_sewer_year, 
                               group = healthbased_violations_5yr)) + 
  geom_point(aes(size = estimate_mhi, color = estimate_poc_alone_per), 
             alpha = 0.6) + 
  theme_minimal() + 
  scale_color_continuous(name = "%POC") + 
  scale_size_continuous(name = "MHI") + 
  labs(x = "Health-based violations (5yr)", y = "Annual Water + Sewer Bill")


# Quick Summary: 
# 4542 pwsids in total 
#   - 703 have had health-based violations over past 5 years (15.48%)
#   - 1201 have had health-based violations over past 10 years (26.44%)
#   
#   - 2673 have had paperwork violations over the past 5 years (58.85)
#   - 3637 have had paperwork violations over the past 10 years (80.07%)
# 
#   Qualitatively, if your mHI is < 100,000 and % POC is < 30%, you're more
#   likely to have more health-based violations over the past 5 years. 
# 
#   When looking at bins of health-based violations over the past 5 years, 
#   most utilities (4484) have less than 25 violations. As the number of 
#   violation increase the MHI decreases. % POC is highest at low levels of 
#   health-based violations, but that might be because the total number of
#   utilities that fall within this category is higher. 

# After splitting the data into more equal bins (deciles): 
# MHI appears to decrease as quantile increases, and % poc decreases
```

## What kind of violations has the system reported? 
```{r}
# SDWIS violations: 
viols <- wds$sdwis %>%
  filter(viol_year >= (year(Sys.Date()) - 10))
# codes from SDWIS: 
sdwis_codes <- aws.s3::s3read_using(read.csv, 
                            object = "s3://tech-team-data/state-drinking-water/TX/raw/SDWA_REF_CODE_VALUES.csv") %>%
  janitor::clean_names()

###############################################################################
# Looking at violation codes: 
###############################################################################
# grabbing just violation codes & merging: 
violation_codes <- sdwis_codes %>%
  filter(value_type == "VIOLATION_CODE")

viol_type <- merge(viols, violation_codes, 
                   by.x = "violation_code", 
                   by.y = "value_code")


# what are the most common violations?
viol_type_summary <- viol_type %>%
  group_by(value_description, is_health_based_ind) %>%
  count()

ggplot(viol_type_summary, aes(x = value_description, y = n, 
                              fill = is_health_based_ind)) + 
  geom_bar(stat = "identity") + 
  coord_flip() + 
  theme_minimal()

# what are the most common violations in East TX?
etx_summary <- viol_type %>%
  left_join(keys$analysis_keys) %>%
  filter(east_tx_flag == "yes")%>%
  group_by(value_description, is_health_based_ind) %>%
  count()

etx_summary <- etx_summary[order(etx_summary$n),] %>%
  filter(n>=30)
ggplot(etx_summary, aes(x = reorder(value_description, -n),
                        y = n, 
                        fill = is_health_based_ind)) + 
  geom_bar(stat = "identity") + 
  scale_fill_discrete(name = "Health-based?") + 
  coord_flip() + 
  theme_minimal() + 
  labs(y = "Number of Violations", x = "Type of Violation")

# really most of them are monitoring violations (48,812), 
# followed by public notification violation for NPDWR (26,152), 
# followed by MCL (18,062)
# and monitoring and reporting: (14,679)

###############################################################################
# Looking at contaminant codes: 
###############################################################################
cont_codes <- sdwis_codes %>%
  filter(value_type == "CONTAMINANT_CODE") %>%
  rename(cont_code = value_code, 
         cont_type = value_type, 
         cont_desc = value_description)

cont_viol_type <- merge(viol_type, cont_codes, 
                        by.x = "contaminant_code", 
                        by.y = "cont_code")

# quick summary of how common each are: 
cont_type_summary <- cont_viol_type %>%
  group_by(value_description, cont_desc, is_health_based_ind) %>%
  count()

ggplot(cont_type_summary, aes(x = value_description, y = n, 
                              fill = is_health_based_ind)) + 
  geom_bar(stat = "identity") + 
  coord_flip() + 
  theme_minimal()

# what about just in East TX?
etx_summary <- cont_viol_type %>%
  left_join(keys$analysis_keys) %>%
  filter(east_tx_flag == "yes") %>%
  group_by(value_description, cont_desc, is_health_based_ind) %>%
  summarize(count = length(unique(pwsid)), 
            per_poc = mean(estimate_poc_alone_per, na.rm = T)) %>%
  mutate(viol_cont = paste0(value_description, " : ", cont_desc), 
         viol_cont = gsub("Consumer Confidence Report", "CCR", viol_cont), 
         viol_cont = gsub("Maximum Contaminant Level", "MCL", viol_cont)) 

# plotting top few: 
etx_summary_filt <- etx_summary[order(etx_summary$count),] %>%
  filter(count > 55)
  # filter(count>=300)
ggplot(etx_summary_filt, aes(x = reorder(viol_cont, -count),
                        y = count, 
                        fill = is_health_based_ind)) + 
  geom_bar(stat = "identity") + 
  scale_fill_discrete(name = "Health-based?") + 
  coord_flip() + 
  theme_minimal() + 
  labs(y = "Total Number of Violations", 
       x = "Violation & Contaminant")


# would love to plot by most common violation by pwsid: 
etx_viols <- cont_viol_type %>%
  left_join(keys$analysis_keys) %>%
  filter(east_tx_flag == "yes") %>%
  mutate(viol_cont = paste0(value_description, ": ", cont_desc), 
         viol_cont = gsub("Consumer Confidence Report", "CCR", viol_cont), 
         viol_cont = gsub("Maximum Contaminant Level", "MCL", viol_cont)) %>%
  group_by(pwsid, viol_cont) %>%
  summarize(total_viol = n())

top_viol <- etx_viols %>%
  group_by(pwsid) %>%
  top_n(1, total_viol) %>%
  slice(which.max(total_viol)) %>%
  left_join(keys$analysis_keys) %>%
  st_as_sf() %>%
  st_transform('+proj=longlat +datum=WGS84' )

# mapping violations:
viol_pal <- colorFactor(
  palette = viridis::viridis(9),
  domain = top_viol$viol_cont)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels, group = "Toner Lite") %>%
  addPolygons(data = top_viol,
              fillOpacity = 0.9,
              stroke = TRUE,
              color = "black",
              fillColor = ~viol_pal(viol_cont),
              weight = 1,
              label = paste0("pwsid: ", top_viol$pwsid,
                "; top viol & cont: ", top_viol$viol_cont)) %>%
  addLegend("bottomright",
            pal = viol_pal,
            values = top_viol$viol_cont,
            title = "Most Common Contaminant")


# are there any relationships between primary water source 
# and types of violations? 
source <- demo$census %>% 
  select(pwsid, primary_source_code) %>%
  as.data.frame() %>%
  select(-geometry)

source_summary <- demo$census %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(primary_source_code) %>%
  summarize(total_pulling = length(unique(pwsid)))

top_viol_source <- top_viol %>%
  as.data.frame() %>%
  select(-geometry) %>%
  left_join(source) %>%
  group_by(viol_cont, primary_source_code) %>%
  summarize(total_pwsids = length(unique(pwsid))) %>%
  left_join(source_summary, by = "primary_source_code") %>%
  mutate(total_pct = 100*(total_pwsids / total_pulling))

ggplot(top_viol_source, aes(x = viol_cont, y = total_pct, 
                            color = primary_source_code)) + 
  geom_point(size = 4, alpha = 0.7) + 
  coord_flip() + 
  theme_minimal() + 
  labs(y = "% of Utilities Pulling from Primay Source", 
       x = "Top Violation and Contaminant") + 
  scale_color_discrete(name = "Water Source")


```

## Has the system been on a water shortage notice? 
```{r}
# grabbing water shortages and analysis keys: 
shortages <- wds$water_restrictions
analysis_keys <- keys$analysis_keys %>%
  st_transform('+proj=longlat +datum=WGS84') 

# merging shortage information with key stats: 
pwsid_shortages <- merge(analysis_keys, shortages, by = "pwsid", 
                         all.y = TRUE) %>%
  st_as_sf() %>%
  st_transform('+proj=longlat +datum=WGS84') %>%
  filter(!st_is_empty(.))

# mapping to see where these 2023 shortages are located: 
leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels, group = "Toner Lite") %>%
  addPolygons(data = analysis_keys,
                # filter(east_tx_flag == "yes"),
              color = "grey", 
              opacity = 1, 
              weight = 1) %>%
  addPolygons(data = pwsid_shortages,
                # filter(east_tx_flag == "yes"),
              color = "darkred", 
              opacity = 1, 
              weight = 1) %>%
  addLegend("bottomright", 
            colors = c("darkred"),
            labels = c(""),
            title = "2023 Water Shortage",
            opacity = 1) 

###############################################################################
# what about just East TX?
###############################################################################
east_tx_shortages <- pwsid_shortages %>%
  filter(east_tx_flag == "yes")

# what are the characteristics of communities on a short water
# notice? 
etx_short <- pwsid_shortages %>%
  filter(east_tx_flag == "yes") %>%
  summarize(mean_poc = mean(estimate_poc_alone_per), 
            mean_mhi = mean(estimate_mhi, na.rm = T), 
            mean_hbv_5 = mean(healthbased_violations_5yr), 
            mean_hbv_10 = mean(healthbased_violations_10yr), 
            mean_pw_5 = mean(paperwork_violations_5yr), 
            mean_pw_10 = mean(paperwork_violations_10yr))

# how does this compare to all pwsids? 
analysis_keys %>%
  filter(east_tx_flag == "yes") %>%
  summarize(mean_poc = mean(estimate_poc_alone_per, na.rm = T), 
            mean_mhi = mean(estimate_mhi, na.rm = T), 
            mean_hbv_5 = mean(healthbased_violations_5yr), 
            mean_hbv_10 = mean(healthbased_violations_10yr), 
            mean_pw_5 = mean(paperwork_violations_5yr), 
            mean_pw_10 = mean(paperwork_violations_10yr))
```

## What is the proximity to water-realted hazards? 
```{r}
# grabbing data from EJ screen: 
ejscreen <- demo$ejscreen %>%
  select(-X)

analysis_keys <- as.data.frame(keys$analysis_keys) %>% 
  select(-geometry)

etx_pwsids <- analysis_keys %>%
  filter(east_tx_flag == "yes") %>%
  as.data.frame() %>%
  distinct(pwsid)

# Superfund sites (NPL), risk management plan (RMP) proximity, 
# haz waste (TSDF and LQGs) proximity, underground storage tanks (UST), 
# and waste water discharges indicator 
water_haz <- ejscreen %>%
  select(oid, id, pnpl, prmp, ptsdf, ust, pwdis) %>%
  rename(superfund = pnpl, 
         rmp = prmp, 
         haz_waste = ptsdf, 
         storage_tanks = ust, 
         waste_discharge = pwdis)

# need census tract geographies for areal interpolation:  
tract_geo <- tidycensus::get_acs(
  geography = "tract", 
  variables = c(total_pop = "B01003_001"), 
  state = c("TX"), 
  year = 2020,
  geometry = TRUE
)

ejscreen_geo <- merge(water_haz, tract_geo, by.x = "id", by.y = "GEOID")

# using areal weighted interpolation to calculate the % of tract that 
# is disadv by area - should just do areal interpolation
ejscreen_geo <- ejscreen_geo %>%
  st_as_sf() %>%
  st_transform(., crs = "ESRI:102296") 

census_sf <- census %>%
  st_transform(., crs = "ESRI:102296") %>%  
  filter(!st_is_empty(.))%>%
  select(pwsid, geometry)

interpolate <- areal::aw_interpolate(census_sf, tid="pwsid", 
                                     source=ejscreen_geo, 
                                     sid="id", 
                                     weight = "sum",
                                     output="sf",
                                     intensive=c("superfund", "rmp", "haz_waste", 
                                                 "storage_tanks", "waste_discharge"))



# what's the relationship between these distances and violations? 
ej_haz_long <- pivot_longer(interpolate, haz_waste:waste_discharge) %>%
  left_join(analysis_keys) %>%
  filter(east_tx_flag == "yes")
ej_haz_long$name <- as.factor(ej_haz_long$name)
levels(ej_haz_long$name) <- c("Haz Waste", "RMP", 
                              "Storage Tanks", "Superfund", 
                              "Waste Discharge")
ggplot(ej_haz_long, aes(x = value, 
                        y = estimate_poc_alone_per)) + 
                        # y = heatlhbased_violations_5yr, 
                        # color = estimate_poc_alone_per)) + 
  geom_point(alpha = 0.5) + 
  geom_point(data = ej_haz_long %>% filter(healthbased_violations_10yr > 0),
             color = "red", alpha = 0.5) +
  # geom_smooth(data = ej_haz_long %>% filter(healthbased_violations_5yr > 0),
  #            color = "red", alpha = 0.5) +
  facet_wrap(~name, scales = "free") + 
  theme_minimal() + 
  # scale_color_continuous(name = "%POC") + 
  labs(x = "Distance to Hazard", y = "%POC")

# grabbing summary stats to reflect this: 
interpolate %>%
  as.data.frame() %>%
  select(-geometry) %>%
  left_join(keys$analysis_keys) %>%
  filter(east_tx_flag == "yes") %>%
  mutate(dist_bin = cut(waste_discharge, 
                       breaks = c(quantile(waste_discharge, 
                                           probs = seq(0, 1, by = 0.20), 
                                           na.rm = TRUE)), 
                       include.lowest = TRUE)) %>%
  group_by(dist_bin) %>%
  summarize(total_utilities = n(),
            paperwork_10yr = mean(paperwork_violations_10yr), 
            paperwork_5yr = mean(paperwork_violations_5yr), 
            health_10yr = mean(healthbased_violations_10yr), 
            health_5yr = mean(healthbased_violations_5yr), 
            mean_mhi = mean(estimate_mhi, na.rm = T), 
            mean_poc = mean(estimate_poc_alone_per, na.rm = T)) %>%
  mutate(quantile = c("0-20","20-40","40-60","60-80","80-100", "NA")) %>%
  relocate(quantile, .after = dist_bin)


# what about general mean distance to a hazard? 
ej_haz_weighted <- as.data.frame(interpolate) 
names(ej_haz_weighted) <- c("pwsid", "haz_waste_weighted", 
                            "rmp_weighted", "storage_tanks_weighted", 
                            "superfund_weighted", "waste_discharge_weighted", 
                            "geometry")
ej_summary <- ej_haz_weighted %>%
  mutate(mean_weighed_all = rowMeans(select(ej_haz_weighted, 
                                            ends_with("_weighted")), 
                                     na.rm = TRUE)) %>%
  st_as_sf() %>%
  st_transform('+proj=longlat +datum=WGS84') %>%
  filter(pwsid %in% etx_pwsid$pwsid)
# wow some of these are close

ej_pal <- colorBin(
  palette = c("#003049","#6b2c39", "#d62828", "#f77f00", "#fcbf49"),
  # bins = c(1, 2, 3, 5, 10, 35), 
  bins = c(0.5, 1, 1.5, 2, 3, 5),
  na.color = "#c9c9bc")
leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels, group = "Toner Lite") %>%
  addPolygons(data = ej_summary,
              fillOpacity = 0.9,
              stroke = TRUE,
              color = "black",
              fillColor = ~ej_pal(mean_weighed_all),
              weight = 1,
              label = paste0("pwsid: ", ej_summary$pwsid,
                "; prox: ", round(ej_summary$mean_weighed_all, 2))) %>%
  addLegend("bottomright",
            pal = ej_pal,
            values = ej_summary$mean_weighed_all,
            title = "Mean Prox to Water Hazards",
            opacity = 1)


# are these proximities significantly correlated with anything? 
viols_data <- keys$analysis_keys %>%
  select(pwsid, paperwork_violations_10yr, healthbased_violations_10yr, 
         paperwork_violations_5yr, healthbased_violations_5yr) %>%
  as.data.frame() %>%
  select(-geometry)

corr_ejhaz <- interpolate %>%
  as.data.frame() %>%
  select(-geometry) %>%
  left_join(demo$census, by = "pwsid") %>%
  left_join(viols_data, by = "pwsid") %>%
  filter(east_tx_flag == "yes")

all_cor <- cor(corr_ejhaz %>% 
                 select(c(healthbased_violations_5yr,
                          paperwork_violations_5yr, 
                          healthbased_violations_10yr,
                          paperwork_violations_10yr,
                          haz_waste,
                          rmp, 
                          storage_tanks, 
                          superfund,
                          waste_discharge,
                          # area_miles, pop_density,
                          # service_connections_count,
                          estimate_mhi, 
                          estimate_hh_below_pov_per,
                          estimate_laborforce_unemployed,
                          estimate_no_school_per,
                          # estimate_high_school_per,
                          estimate_only_english_per,
                          estimate_foreign_per,
                          estimate_hisp_alone_per,
                          estimate_poc_alone_per)) %>% 
                 rename_with(~ str_remove(., "_alone_per"),
                             everything()) %>%
                          rename_with(~ str_remove(., "_per"), 
                                      everything()) %>%
                          rename_with(~ str_remove(., "estimate"),
                                      everything()) %>%
                          rename_with(~ str_remove(., "_"), 
                                      everything()), 
               use = "pairwise.complete.obs") 

name_changes <- c("Health Violations, 5yr", "Non-Health Violations, 5yr", 
                  "Health Violations, 10yr",  "Non-Health Violations, 10yr", 
                  "Hazardous Waste", "Risk Management Plan", 
                  "Storage Tanks", "Superfund", 
                  "Waste Discharge",
                  "Median Household Income", "% Households in Poverty", 
                  "% Unemployment", "% No Schooling", 
                  "% Only Speak English",
                  "% Immigrant", "% Latino/a", "% POC")

rownames(all_cor) <- name_changes
colnames(all_cor) <- name_changes

cor_pvals <- cor.mtest(all_cor, conf.level = 0.95)
cor_pvals$p

corrplot(all_cor, method = 'color', type = 'upper', 
         p.mat = cor_pvals$p, 
         sig.level = c(0.01, 0.05), pch.cex = 0.9,
         insig = 'label_sig', pch.col = 'grey20',
         # insig = "p-value", 
         # sig.level = -1, 
         mar=c(0,0,0,0), 
         tl.col = "black", 
         diag = FALSE)

```

## How many boil water notices have there been over the past five years?
```{r}
bwn_f1 <- wds$bwn_f1 %>%
  rename(pwsid = wsid)
bwn_f2 <- wds$bwn_f2 %>%
  rename(pwsid = pws_id)

# combining with key vars: 
key_vars <- keys$analysis_keys

pws_bwn <- key_vars %>%
  left_join(bwn_f2, by = "pwsid") %>%
  filter(east_tx_flag == "yes")

# grouping and summarizing: 
pws_summary <- pws_bwn %>%
  group_by(pwsid) %>%
  summarize(total = length(unique(updtts))) %>%
  st_transform('+proj=longlat +datum=WGS84')

etx_sabs <- demo$census %>%
  filter(east_tx_flag == "yes") %>%
  st_transform('+proj=longlat +datum=WGS84')

# mapping number of bwn:
bwn_pal <- colorNumeric(
  palette = viridis::inferno(9),
  domain = pws_summary$total)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels, group = "Toner Lite") %>%
   addPolygons(data = etx_sabs,
              opacity = 0.8,
              color = "grey", 
              weight = 1) %>%
  addPolygons(data = pws_summary,
              fillOpacity = 0.9,
              stroke = TRUE,
              color = "black",
              fillColor = ~bwn_pal(total),
              weight = 1,
              label = paste0("pwsid: ", pws_summary$pwsid,
                             "; bwn: ", pws_summary$total)) %>%
  addLegend("bottomright",
            pal = bwn_pal,
            values = pws_summary$total,
            title = "BWN",
            opacity = 1)
```

## Have there been any enforcement actions?
```{r}
census <- demo$census
# TODO: add this enforcement action function to the R package: 
sdwis_enf <- get_SDWIS_enforcement(pwsids = census$pwsid)

# summarizing data by five and ten years: 
enf_summary_5yr <- sdwis_enf %>%
  filter(enf_year >= year(Sys.Date())-5) %>%
  group_by(pwsid) %>%
  summarize(enf_5yr = length(unique(enforcement_id))) 

enf_summary_10yr <- sdwis_enf %>%
  filter(enf_year >= year(Sys.Date())-10) %>%
  group_by(pwsid) %>%
  summarize(enf_10yr = length(unique(enforcement_id))) 

enf_summary <- merge(enf_summary_10yr, 
                     enf_summary_5yr, by = "pwsid", 
                     all.x = T) %>%
  mutate(enf_5yr = replace_na(enf_5yr, 0))

# combining with the rest of the pwsids that don't have any 
# enforcement actions: 
sdwis_enf_all <- merge(enf_summary, 
                       keys$analysis_keys, by = "pwsid", 
                       all.y = T) %>%
  mutate(enf_5yr = replace_na(enf_5yr, 0), 
         enf_10yr = replace_na(enf_10yr, 0))

summary(sdwis_enf_all)

# what percentage of pwsids have an enforcement action over the past 5yrs? 
sdwis_enf_all %>%
  filter(enf_10yr > 0) %>%
  count()

# plotting enforcement actions by violation type: 
enf_viol_summary <- sdwis_enf_all %>%
  pivot_longer(paperwork_violations_10yr:total_violations_5yr)
enf_viol_summary$name <- as.factor(enf_viol_summary$name)
levels(enf_viol_summary$name) <- c("Health, 10yr", 
                                   "Health, 5yr", 
                                   "Non-Health, 10yr", 
                                   "Non-Health, 5yr", 
                                   "Total, 10yr", 
                                   "Total, 5yr") 
enf_viol_summary <- enf_viol_summary %>%
  filter(name %in% c("Health, 5yr", "Non-Health, 5yr", 
                     "Total, 5yr"))
ggplot(enf_viol_summary,
         # filter(east_tx_flag == "yes"), 
       aes(x = enf_5yr, 
                             y = value, 
                             group = name, 
                             color = estimate_mhi, 
                             size = estimate_poc_alone_per)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  facet_wrap(~name, scales = "free") + 
  scale_color_continuous(name = "MHI") + 
  scale_size_continuous(name = "%POC") + 
  theme_minimal() +
  labs(x = "Enforcement Actions, 5yr", y = "# by Violation Type")

# checking out just health-based violations in relation to POC and MHI:
ggplot(sdwis_enf_all, aes(x = enf_5yr, 
                          y = healthbased_violations_5yr, 
                          color = estimate_mhi)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  theme_minimal() +
  labs(x = "Enforcement Actions, 5yr", y = "Health-based Violations, 5yr")

ggplot(sdwis_enf_all, aes(x = enf_5yr, 
                          y = healthbased_violations_5yr, 
                          color = estimate_poc_alone_per)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  theme_minimal() +
  labs(x = "Enforcement Actions, 5yr", y = "Health-based Violations, 5yr")

# checking this out as a table: 
sdwis_enf_all %>%
    as.data.frame() %>%
    select(-geometry) %>%
    mutate(enf_bin = cut(enf_5yr, 8)) %>%
    group_by(enf_bin) %>%
    summarize(total_utilities = n(),
              mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_poc = mean(estimate_poc_alone_per, na.rm = T))

# by quantiles:
sdwis_enf_all %>%
  as.data.frame() %>%
  select(-geometry) %>%
  mutate(enf_bin = cut(enf_5yr, 
                       breaks = c(unique(quantile(enf_5yr, 
                                                  probs = seq(0, 1, by = 0.1), 
                                                  na.rm = TRUE))), 
                       include.lowest = TRUE)) %>%
  group_by(enf_bin) %>%
  summarize(total_utilities = n(),
            paperwork_10yr = mean(paperwork_violations_10yr), 
            paperwork_5yr = mean(paperwork_violations_5yr), 
            health_10yr = mean(healthbased_violations_10yr), 
            health_5yr = mean(healthbased_violations_5yr), 
            mean_mhi = mean(estimate_mhi, na.rm = T), 
              mean_poc = mean(estimate_poc_alone_per, na.rm = T))
  

# Overall findings: 
# - 2928 (64.46%) of pwsids have had an enforcement action over the past 
#   5 years, and 3930 (86.53%) over the past 10 years. 
# 
# - mean enforcement actions over the past 10 years: 42.6, and 20.7 over 
#   the past 5 years. However, these data are highly skewed. 
# 
# - to no surprise, more health-based violations also indicate more 
#   enforcement actions, but there's alone line that appears where there 
#   are more enforcement actions but no health-based violations (possible these 
#   violations are paperwork instead)
# 
# - there is a strong linear relationship between the number of enforcement 
#   actions and the number of total violations over the past 5 and 10 years. 
# 
# - Visually it appears that paperwork violations (in comparison to health based) 
#   often result in a enforcement action
# 
# - utilities with low enforcement actions over the last 5 years have a 
#   higher MHI and %POC

```

## What is the Climate Vulerability Index?
```{r}
# NOTE: CVI is based on 2010 geographies
# grabbing CVI, analysis keys, and crosswalk: 
cvi_tidy <- demo$cvi %>%
  select(-X) %>%
  rename(census_tract = fips_code)

tract_2010_2020_crosswalk <- read.table("https://www2.census.gov/geo/docs/maps-data/data/rel2020/tract/tab20_tract20_tract10_natl.txt", 
                                        sep = "|", header = TRUE)

cvi_crosswalk <- merge(cvi_tidy, tract_2010_2020_crosswalk, 
                        by.x = "census_tract", 
                        by.y = "GEOID_TRACT_10", all.x = TRUE)

# loading analysis keys:
analysis_keys <- keys$analysis_keys

# need census tract geographies for areal interpolation:  
tract_geo <- tidycensus::get_acs(
  geography = "tract", 
  variables = c(total_pop = "B01003_001"), 
  state = c("TX"), 
  year = 2020,
  geometry = TRUE
)

cvi_tidy_final <- merge(tract_geo, cvi_crosswalk, by.x = "GEOID", by.y = "GEOID_TRACT_20", all.y = T)

# using areal weighted interpolation to calculate the % of tract that 
# is disadv by area - should just do areal interpolation
cvi_geo <- cvi_tidy_final %>%
  st_as_sf() %>%
  st_transform(., crs = "ESRI:102296") 

census_sf <- census %>%
  st_transform(., crs = "ESRI:102296") %>%  
  filter(!st_is_empty(.))%>%
  select(pwsid, geometry)

interpolate <- areal::aw_interpolate(census_sf, tid="pwsid", 
                                     source=cvi_geo, 
                                     sid="census_tract", 
                                     weight = "sum",
                                     output="sf",
                                     intensive=c("overall_cvi_score"))

cvi_weighted <- interpolate %>%
  rename(cvi_weighted_score = overall_cvi_score)

# what's the mean cvi for utilities?
mean(cvi_weighted$cvi_weighted_score, na.rm = T)
median(cvi_weighted$cvi_weighted_score, na.rm = T)

etx_cvi <- cvi_weighted %>%
  as.data.frame() %>%
  select(-geometry) %>%
  left_join(keys$analysis_keys) %>%
  filter(east_tx_flag == "yes") %>%
  select(pwsid, cvi_weighted_score, east_tx_flag, geometry) %>%
  st_as_sf() %>%
  st_transform('+proj=longlat +datum=WGS84' )
mean(etx_cvi$cvi_weighted_score, na.rm = T)
median(etx_cvi$cvi_weighted_score, na.rm = T)

# mapping CVI:
cvi_pal <- colorNumeric(
  palette = viridis::mako(9),
  domain = etx_cvi$cvi_weighted_score)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels, group = "Toner Lite") %>%
  addPolygons(data = etx_cvi,
              fillOpacity = 0.9,
              stroke = TRUE,
              color = "black",
              fillColor = ~cvi_pal(cvi_weighted_score),
              weight = 1,
              label = paste0("pwsid: ", etx_cvi$pwsid,
                "; cvi: ", round(etx_cvi$cvi_weighted_score, 2))) %>%
  addLegend("bottomright",
            pal = cvi_pal,
            values = etx_cvi$cvi_weighted_score,
            title = "CVI",
            opacity = 1)

# how does systems with high CVI relate to %POC, MHI, and violations?
# assuming strongly correlated with %POC and MHI, since I think these are 
# variables incorporated into the CVI calculation. 
cvi_analysis <- cvi_weighted %>%
  as.data.frame() %>%
  select(-geometry) %>%
  left_join(analysis_keys)

etx_cvi_analysis <- cvi_analysis %>%
  filter(east_tx_flag == "yes")

ggplot(cvi_analysis, aes(x = cvi_weighted_score)) + 
  geom_histogram(fill = "lightblue") + 
  geom_histogram(data = etx_cvi_analysis, fill = "pink") + 
  theme_minimal() + 
  labs(x = "CVI", y = "Number of PWSIDs")

ggplot(cvi_analysis, aes(x = cvi_weighted_score, 
                          y = estimate_mhi)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  theme_minimal() +
  geom_point(data = cvi_analysis %>% 
               filter(healthbased_violations_5yr>0), 
             color = "red") +
  geom_smooth(data = cvi_analysis %>% 
                filter(healthbased_violations_5yr>0), 
             color = "red") + 
  labs(x = "CVI", y = "MHI") 

ggplot(cvi_analysis, aes(x = cvi_weighted_score, 
                          y = estimate_poc_alone_per)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  theme_minimal() +
  geom_point(data = cvi_analysis %>% 
               filter(healthbased_violations_5yr>0), 
             color = "red") +
  geom_smooth(data = cvi_analysis %>% 
                filter(healthbased_violations_5yr>0), 
             color = "red") + 
  labs(x = "CVI", y = "%POC") 

ggplot(etx_cvi_analysis, aes(x = cvi_weighted_score, 
                          y = estimate_mhi)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  theme_minimal() +
  geom_point(data = etx_cvi_analysis %>% 
               filter(healthbased_violations_5yr>0), 
             color = "red") +
  geom_smooth(data = etx_cvi_analysis %>% 
                filter(healthbased_violations_5yr>0), 
             color = "red") + 
  labs(x = "CVI", y = "MHI") 

ggplot(etx_cvi_analysis, aes(x = cvi_weighted_score, 
                          y = estimate_poc_alone_per)) + 
  geom_point() + 
  geom_smooth(color = "grey") + 
  theme_minimal() +
  geom_point(data = etx_cvi_analysis %>% 
               filter(healthbased_violations_5yr>0), 
             color = "red") +
  geom_smooth(data = etx_cvi_analysis %>% 
                filter(healthbased_violations_5yr>0), 
             color = "red") + 
  labs(x = "CVI", y = "%POC")


# checking out binned results in table form: 
cvi_analysis %>%
    as.data.frame() %>%
    select(-geometry) %>%
    mutate(cvi_bin = cut(cvi_weighted_score, 5)) %>%
    group_by(cvi_bin) %>%
    summarize(total_utilities = n(),
              paperwork_10yr = mean(paperwork_violations_10yr), 
              paperwork_5yr = mean(paperwork_violations_5yr), 
              health_10yr = mean(healthbased_violations_10yr), 
              health_5yr = mean(healthbased_violations_5yr)) 

# by quantile: 
cvi_analysis %>%
  as.data.frame() %>%
  select(-geometry) %>%
  filter(east_tx_flag == "yes") %>%
  mutate(cvi_bin = cut(cvi_weighted_score, 
                       breaks = c(quantile(cvi_weighted_score, 
                                           probs = seq(0, 1, by = 0.20), 
                                           na.rm = TRUE)), 
                       include.lowest = TRUE)) %>%
  group_by(cvi_bin) %>%
  summarize(total_utilities = n(),
            paperwork_10yr = mean(paperwork_violations_10yr), 
            paperwork_5yr = mean(paperwork_violations_5yr), 
            health_10yr = mean(healthbased_violations_10yr), 
            health_5yr = mean(healthbased_violations_5yr), 
            mean_mhi = mean(estimate_mhi, na.rm = T), 
            mean_poc = mean(estimate_poc_alone_per, na.rm = T)) %>%
  mutate(quantile = c("0-20","20-40","40-60","60-80","80-100")) %>%
  relocate(quantile, .after = cvi_bin)


# is this correlated with anything? 
all_cor <- cor(cvi_analysis %>% 
                 filter(east_tx_flag == "yes") %>%
                 select(c(healthbased_violations_5yr,
                          paperwork_violations_5yr, 
                          paperwork_violations_10yr,
                          healthbased_violations_10yr,
                          estimate_mhi, 
                          estimate_poc_alone_per, 
                          cvi_weighted_score)), 
               use = "pairwise.complete.obs")

cor_pvals <- cor.mtest(all_cor, conf.level = 0.95)
cor_pvals$p

corrplot(all_cor, method = 'ellipse', type = 'upper', 
        p.mat = cor_pvals$p, insig = "p-value", sig.level = -1, 
        mar=c(0,0,0,0))



# Overall findings: 
# - Spatially, CVI is high within cities, decreases in suburban areas, and 
#   increases in rural systems 

# - Most systems (823) fall within CVI values between 0.263-0.394. The mean
#   CVI is 0.31, and the median is 0.32.

# - As CVI increases, mean health-based violations over the past 5 and 10 years
#   increases. 

# - paperwork violations over the past 5 years are higher at utilities with low
#   CVI (which is the opposite of health-based violations).

# - CVI doesn't appear to be tightly related to %POC, but CVI increases with 
#   as MHI decreases

# By quantile: 
#  - Utilities that fall under the highest CVI quantile (0.47 - 0.66), have 
#   lowest MHI, largest health-based violations over the past 5 and 10 years, 
#   and the lowest number of paperwork violations over the past 10 years
```

## Does the system use green energy/focus on green energy?
NOTE: put this question on pause for now (3/21/2024)
```{r}
# We might be able to answer this with some of the IUP GPR data... 
iup <- fin$TX_PPL_SFY14_24 %>%
  rename(pwsid = pws_id)
```

## How much water loss does the system have?
NOTE: put this question on pause for now (3/21/2024) - data are weird
```{r}
# real loss GMD = gallons/mile/day 
# GCD = gallons/connection/day 
# ILI = Infrastructure leakage index 
# GPCD = gallons per capita per day 
# this is NOT a comprehensive list - I believe it's just for utilities 
# with more than 3,300 connections 
# 
# apparent loss = paper losses when water reaches a customer but the volume 
#   is not accurately measured due to meter inaccuracy 
# real loss = physical loss from infrastructure leakage - occur prior to 
#   reaching the customer (we care more about these, right?!)
all_wl <- wds$water_loss

# water loss audits just have system name - need to prep the data for string 
# matching: 
pwsid_keys <- demo$census %>%
  select(pwsid, pws_name) %>%
  mutate(pws_name_tidy = str_to_upper(pws_name), 
         pws_name_tidy = str_squish(pws_name_tidy), 
          # remove hyphens 
         pws_name_tidy = gsub("-", "", pws_name_tidy), 
         # remove all spaces 
         pws_name_tidy = gsub(" ", "", pws_name_tidy), 
         # remove #
         pws_name_tidy = gsub("#", "", pws_name_tidy)) %>%
  unique() %>%
  select(-pws_name)

# grabbing water loss audit data: 
wl <- wds$water_loss %>%
  janitor::clean_names() %>%
  select(year, name_of_utility, real_loss_gcd, real_loss_cost_in_dollars, 
         apparent_loss_cost_in_dollars) %>%
  mutate(name_of_utility_tidy = str_to_upper(name_of_utility), 
         name_of_utility_tidy = str_squish(name_of_utility_tidy), 
           # remove hyphens 
         name_of_utility_tidy = gsub("-", "", name_of_utility_tidy), 
         # remove all spaces 
         name_of_utility_tidy = gsub(" ", "", name_of_utility_tidy), 
         # remove #
         name_of_utility_tidy = gsub("#", "", name_of_utility_tidy))

# matching names and pwsids: 
wl_pwsids <- merge(wl, pwsid_keys,
                   by.x = "name_of_utility_tidy", by.y = "pws_name_tidy", 
                   all.x = TRUE)
# 2,773 water systems 
  
# how many don't have a name match? 200
missing_pwsid <- wl_pwsids %>%
  filter(is.na(pwsid)) %>%
  select(name_of_utility_tidy) %>%
  unique()

# pulling name matches from a webscrape: https://dww2.tceq.texas.gov/DWW/JSP/SearchDispatch?number=&name=&ActivityStatusCD=All&county=All&WaterSystemType=All&SourceWaterType=All&SampleType=null&begin_date=2%2F8%2F2022&end_date=2%2F8%2F2024&action=Search+For+Water+Systems
URL <- "https://docs.google.com/spreadsheets/d/1Ds2GeJ8AMWqhBKRcIAXgO0Po8c9l_syVz4JFkeCNyXk/edit#gid=0"
dl <- googledrive::drive_download(
  as_id(URL),
  path = 'temp1.xlsx', 
  type = "xlsx")
pwsid_names <- readxl::read_excel('temp1.xlsx', col_names = TRUE) %>%
  janitor::clean_names() %>%
  mutate(water_system_name = str_to_upper(water_system_name), 
         water_system_name = str_squish(water_system_name)) 
file.remove("temp1.xlsx")

# removing fact sheet summary string and tidying before name merge: 
pwsid_names$utility_name_tidy <- unlist(strsplit(pwsid_names$water_system_name, " FACT SHEET SUMMARY SHEET"))
pwsid_names_tidy <- pwsid_names %>% select(water_system_no, utility_name_tidy) %>%
  rename(pwsid = water_system_no) %>%
  # remove hyphens 
  mutate(utility_name_tidy = gsub("-", "", utility_name_tidy), 
         # remove all spaces 
         utility_name_tidy = gsub(" ", "", utility_name_tidy), 
         # remove #
         utility_name_tidy = gsub("#", "", utility_name_tidy))
       
match_names <- merge(missing_pwsid, pwsid_names_tidy, by.x = "name_of_utility_tidy", 
      by.y = "utility_name_tidy", all.x = TRUE) %>%
  filter(!is.na(pwsid))

# recombining: 
all_pwsid_names <- merge(wl_pwsids, match_names, by = "name_of_utility_tidy", all.x = TRUE) %>%
  mutate(pwsid = case_when(
    is.na(pwsid.x) ~ pwsid.y, 
    is.na(pwsid.y) ~ pwsid.x, 
    TRUE ~ "no match"
  )) %>%
  select(-c(pwsid.x, pwsid.y))

# there are still 115 pwsids missing: 
all_pwsid_names %>%
  filter(is.na(pwsid)) %>%
  distinct(name_of_utility_tidy)

# pulling in TCEQ historical names for help: 
hist_names <- aws.s3::s3read_using(read.csv, 
                                  object = "s3://tech-team-data/state-drinking-water/TX/raw/TX_TCEQ_DWW/TX_20231217/WaterSystemDetail/TX_Water System Historical Names_20231217_20231229203427.csv")

hist_names_p2 <- 
  aws.s3::s3read_using(read.csv, 
                                  object = "s3://tech-team-data/state-drinking-water/TX/raw/TX_TCEQ_DWW/TX_20231203/WaterSystemDetail/TX_Water System Historical Names_20231203.csv")

all_hist_names <- rbind(hist_names, hist_names_p2) %>%
  janitor::clean_names() %>%
  # remove hyphens 
  mutate(historical_name_s = gsub("-", "", historical_name_s), 
         # remove all spaces 
         historical_name_s = gsub(" ", "", historical_name_s), 
         # remove #
         historical_name_s = gsub("#", "", historical_name_s))

# YEEHAW!!!
all_name_matches <- merge(all_pwsid_names, all_hist_names, 
                          by.x = "name_of_utility_tidy", 
                          by.y = "historical_name_s", all.x = TRUE) %>%
  mutate(final_pwsid = paste0(pwsid, water_system_no), 
         final_pwsid = gsub("NA", "", final_pwsid)) %>%
  # catching instances where the name matched with both datasets: 
  mutate(final_pwsid = 
           case_when(
             pwsid == water_system_no ~ pwsid, 
             TRUE ~ final_pwsid
           )) %>%
  # fixing matches where the pwsids are NOT identical - did this through 
  # some google searches: 
  mutate(final_pwsid = case_when(
    # the Arrowhead water system in Hill county is different from this one: 
    name_of_utility == "Arrowhead Water System" ~ pwsid, 
    name_of_utility == "Bolivar WSC" ~ pwsid, 
    name_of_utility == "CITY OF ARCOLA" ~ pwsid, 
    # different from the Morgans Point Resort
    name_of_utility == "CITY OF MORGANS POINT" ~ pwsid, 
    name_of_utility == "ELM RIDGE WCID" ~ pwsid, 
    name_of_utility == "Green Acres Mobile Home Park" ~ pwsid, 
    name_of_utility == "Harris County MUD 49" ~ pwsid, 
    name_of_utility == "Pleasant Hill WSC" ~ pwsid, 
    name_of_utility == "Woodland Oaks Subdivision" ~ pwsid, 
    name_of_utility %in% c("THE COMMONS WATER SUPPLY INC", 
                           "The Commons Water Supply Inc") ~ water_system_no, 
    # these below just didn't match but easy to do by hand: 
    name_of_utility == "CITY OF MCALLEN" ~ "TX1080006",
    name_of_utility %in% c("Fort Bend Co MUD # 42 Water Plant", 
                           "FORT BEND COUNTY MUD 42") ~ "TX0790254",
    TRUE ~ final_pwsid))

# NOTE: there are three: 
# - HARRIS COUNTY UTILITY DISTRICT 14 and 15 
# - LCRA WEST TRAVIS COUNTY REGIONAL WS 
# that can't be matched 

# tidying and analysis: 
wl_tidy <- all_name_matches %>%
  select(year, name_of_utility, 
         real_loss_gcd, real_loss_cost_in_dollars, 
         apparent_loss_cost_in_dollars, final_pwsid) %>%
  rename(pwsid = final_pwsid, 
         real_loss = real_loss_cost_in_dollars, 
         appar_loss = apparent_loss_cost_in_dollars) %>%
  mutate(real_loss = readr::parse_number(real_loss), 
         appar_loss = readr::parse_number(appar_loss)) %>%
  left_join(analysis_keys) %>%
  st_as_sf() %>%
  st_transform(., crs = st_crs(census))

# summary stats: 
wl_summary <- wl_tidy %>%
  group_by(pwsid) %>%
  summarize(mean_real_loss = mean(real_loss), 
            mean_appar_loss = mean(appar_loss), 
            mean_poc = mean(estimate_poc_alone_per), 
            mean_mhi = mean(estimate_mhi), 
            mean_health_5yr = mean(healthbased_violations_5yr), 
            mean_real_loss_gcd = mean(as.numeric(real_loss_gcd), na.rm = T))

# plotting relationships: 
wl_tidy_df <- wl_tidy %>%
  as.data.frame() %>%
  select(-geometry) %>%
  mutate(real_loss_gcd = as.numeric(real_loss_gcd)) 
ggplot(wl_tidy_df, aes(x = real_loss_gcd, fill = east_tx_flag)) + 
  geom_histogram() + 
  scale_fill_manual(values = c("yes"="lightpink", "no"="lightblue"), 
                      name = "") +
  theme_minimal() + 
  labs(x = "Mean Real Loss (2010 - 2022) in Gallons/Connections/Day", 
       y = "Number of PWSIDs")

length(unique(wl_tidy_df$pwsid)) # 2981
etx_wl <- wl_tidy_df %>% filter(east_tx_flag == "yes")
length(unique(etx_wl$pwsid))

# getting summary stats: 
wl_tidy_df %>%
  group_by(east_tx_flag) %>%
  summarize(mean_real_loss_gcd = mean(real_loss_gcd), 
            median_real_loss_gcd = median(real_loss_gcd))

# creating some summary plots and comparisons with key stats of interest: 
ggplot(wl_summary, aes(x = mean_mhi, y = mean_real_loss_gcd)) + 
  geom_point(aes(color = mean_poc)) + 
  geom_point(data = wl_summary %>%
               filter(mean_health_5yr > 0), color = "red")

ggplot(wl_summary, aes(x = mean_poc, y = mean_real_loss_gcd)) + 
  geom_point(aes(color = mean_mhi)) + 
  geom_point(data = wl_summary %>%
               filter(mean_health_5yr > 0), color = "red")

ggplot(wl_summary, aes(x = mean_real_loss_gcd, y = mean_health_5yr, 
                       size = mean_poc)) + 
  geom_point() + 
  geom_point(data = wl_summary %>% filter(pwsid %in% etx_wl$pwsid),
             color = "pink") + 
  scale_size_continuous(name = "% POC") + 
  theme_minimal() + 
  labs(x = "Mean Real Loss (2010 - 2022) in Gallons/Connections/Day", 
       y = "Number of Health-based Violations (5yr)")  

ggplot(wl_summary
       %>% filter(pwsid %in% etx_wl$pwsid), 
       aes(x = mean_real_loss_gcd, y = mean_mhi)) + 
  geom_point() + 
  geom_point(data = wl_summary %>% filter(mean_health_5yr > 0 & pwsid %in% etx_wl$pwsid),
             color = "red") + 
  # scale_size_continuous(name = "% POC") + 
  theme_minimal() + 
  labs(x = "Mean Real Loss (2010 - 2022) in Gallons/Connections/Day", 
       y = "MHI")  

ggplot(wl_summary
       %>% filter(pwsid %in% etx_wl$pwsid), 
       aes(x = mean_real_loss_gcd, y = mean_poc)) + 
  geom_point() + 
  geom_point(data = wl_summary %>% filter(mean_health_5yr > 0 & pwsid %in% etx_wl$pwsid),
             color = "red") + 
  # scale_size_continuous(name = "% POC") + 
  theme_minimal() + 
  labs(x = "Mean Real Loss (2010 - 2022) in Gallons/Connections/Day", 
       y = "%POC")  

# geom_point(data = wl_summary %>%
  #              filter(mean_health_5yr > 0), color = "red")

# table of status for each apparent loss bin: 
wl_summary %>%
  as.data.frame() %>%
  select(-geometry) %>%
  mutate(real_loss_bin = cut(mean_real_loss, 
                             breaks = c(quantile(mean_real_loss, 
                                                 probs = seq(0, 1, by = 0.20))), 
                             include.lowest = TRUE)) %>%
  group_by(real_loss_bin) %>%
  summarize(total_utilities = n(),
            mean_poc = mean(mean_poc, na.rm = T), 
            mean_mhi = mean(mean_mhi, na.rm = T), 
            mean_health_5yr = mean(mean_health_5yr, na.rm = T)) %>%
  mutate(quantile = c("0-20","20-40","40-60","60-80","80-100")) %>%
  relocate(quantile, .after = real_loss_bin)

# what does high real loss look like spatially?
wl_summary_sf <- wl_summary %>%
  st_as_sf() %>%
  st_transform(., crs = st_crs(census))

loss_pal <- colorNumeric(
  palette = viridis::mako(9),
  domain = wl_summary_sf$mean_real_loss)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels, group = "Toner Lite") %>%
  addPolygons(data = wl_summary_sf$geometry,
              opacity = 9,
              color = ~loss_pal(mean_real_loss),
              weight = 1,
              label = paste0("pwsid: ",
                             wl_summary_sf$pwsid,
                "; real loss: ", round(wl_summary_sf$mean_real_loss, 2))) %>%
  addLegend("bottomright",
            pal = loss_pal,
            values = wl_summary_sf$mean_real_loss,
            title = "real loss",
            opacity = 1)

# TODO: what has the net change been in mean loss? this would require the min
#   and max year for each utility, since our temporal coverage varies for 
#   each. 


# Overall findings: 
# - mean real loss is $997,000,000; median is $19,050 - so LOTs of skew 
# - mean apparent loss is $845,700,000; median is $10,010
# - visually, highest mean real loss is around mhi OF ~$75,000, and 
#   %POC of ~30%
# - At higher quantiles, % POC increases, but the trend with MHI and mean 
#   health-based viols over the past 5 years is less clear. MHI is largest 
#   at the 80-100% quantile, but also high at the 0-20% quantile. For health
#   based violations over the past 5-years, highest is at 0-20 quantile 
#   and 40-60%
```

## What type of treatment is in use? 
NOTE: put this question on pause for now (3/21/2024) - too incomplete
```{r}
# statewide basis - people pulling from sw are using different treatment 
# techniques than groundwater 
# however - there is likely going to be minimal difference 
#         - chlorine and fluoride and mechanical (membrane)
# double-check 
# filter by counties - the categories would get dropped down to 5 and then 
# determine if it's realisitc or not 

treatments_dec17 <- aws.s3::s3read_using(read.csv, 
                           object = "state-drinking-water/TX/raw/TX_TCEQ_DWW/TX_20231217/WaterSystemFacilities/TX_Treatment Plant Unit Process Flows_20231217_20231229203427.csv",
                           bucket = "tech-team-data") %>%
  clean_names()

treatments_dec03 <- aws.s3::s3read_using(read.csv, 
                           object = "state-drinking-water/TX/raw/TX_TCEQ_DWW/TX_20231203/WaterSystemFacilities/TX_Treatment Plant Unit Process Flows_20231203.csv",
                           bucket = "tech-team-data") %>%
  clean_names()

# this is probably not a comprehensive list 
all_treat <- rbind(treatments_dec03, treatments_dec17)
treat_simple <- all_treat %>%
  filter(water_system_no %in% demo$census$pwsid) %>%
  group_by(water_system_no) %>%
  distinct(supply)

# grabbing the total number of treatment steps: 
treat_steps <- treat_simple %>%
  group_by(water_system_no) %>%
  summarize(treat_steps = n())

ggplot(treat_steps, aes(x = n)) + 
  geom_histogram() + 
  labs(x = "Number of Treatment Steps", y = "Count of PWSIDs")+ 
  theme_minimal()

# combining treatment steps with other information we know about the pwsid: 
pwsid_info <- demo$census
pwsid_info <- pwsid_info %>%
  select(pwsid:primary_source_code)

pwsid_treat <- merge(treat_steps, pwsid_info, 
                     by.x = "water_system_no", by.y = "pwsid",
                     all.y = TRUE) 

ggplot(pwsid_treat, aes(x = treat_steps, color = primary_source_code, 
                        fill = primary_source_code)) + 
  geom_histogram() + 
  facet_wrap(~primary_source_code, scales = "free") + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  labs(x = "Number of Treatment Steps", y = "Number of PWSIDs")

# what's the summary of treatment steps by source water? 
pwsid_treat %>%
  group_by(primary_source_code) %>%
  summarize(total = n(), 
            have_info = sum(!is.na(treat_steps)),
            mean_treat_steps = mean(treat_steps, na.rm = T), 
            median_treat_steps = median(treat_steps, na.rm = T)) %>%
  rename(n = have_info) %>%
  select(-total)


# Overall findings: 
# - the coverage for these data is pretty poor - we only have data for 
#   306 pwsids out of 4542 (~6.7%). Out of these, most of them are pulling 
#   surface water (275), followed by GU (19), which is groundwater under the 
#   influence of surface water
# - for those pulling surface water, they have a mean of 25 treatment steps 
# - utilities pulling SWP has ~6 treatment steps, GU have ~5 and GW 
#   has ~4.
```

## What is the source of water? 
```{r}
###############################################################################
# investigating water source information from SDWIS:
###############################################################################
source <- demo$census
water_source <- source %>%
  select(pwsid, primary_source_code, county_served) %>%
  mutate(type = "TX")

ggplot(water_source, aes(x = primary_source_code, fill = primary_source_code)) +
  theme_minimal() + 
  geom_histogram(stat = "count")+ 
  scale_color_discrete(name = "") + 
  scale_fill_discrete(name = "") + 
  labs(x = "Primary Water Source", y = "Count of PWSIDs")

# adding east TX breakdown: 
etx_source <- source %>%
  filter(east_tx_flag == "yes") %>%
  select(pwsid, primary_source_code, county_served)%>%
  mutate(type = "East TX")

ggplot(etx_source, aes(x = primary_source_code, 
                      fill = primary_source_code)) +
  theme_minimal() + 
  geom_histogram(stat = "count")+ 
  scale_color_discrete(name = "") + 
  scale_fill_discrete(name = "") + 
  labs(x = "Primary Water Source", y = "Count of PWSIDs")

# combining everything for a graph: 
all_tx <- rbind(etx_source, water_source)
demo$census %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(primary_source_code, east_tx_flag) %>%
  count()

ggplot(all_tx, aes(x = primary_source_code, fill = type)) +
  theme_minimal() + 
  geom_bar(position = "identity", alpha = 0.5) +
  geom_bar(data = all_tx %>% filter(type == "East TX"), 
           position = "identity", alpha = 0.5) +
  scale_color_discrete(name = "") + 
  scale_fill_discrete(name = "") + 
  labs(x = "Primary Water Source", y = "Count of PWSIDs")

# also interested in seeing how this relates to actual population: 
tx_pop <- sum(demo$census$estimate_total_pop, na.rm = T)
etx_pop <- demo$census %>% 
  filter(east_tx_flag == "yes") %>%
  summarize(total_pop = sum(estimate_total_pop, na.rm = T))

pop_source_tx <- demo$census %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(primary_source_code) %>%
  summarize(total_sabs = length(unique(pwsid)),
            pop_served = sum(estimate_total_pop, na.rm = T)) %>%
  mutate(percent_pop = 100*(pop_served/tx_pop), 
         flag = "TX") 

pop_source_etx <- demo$census %>%
  as.data.frame() %>%
  select(-geometry) %>%
    filter(east_tx_flag == "yes") %>%
  group_by(primary_source_code) %>%
  summarize(total_sabs = length(unique(pwsid)),
            pop_served = sum(estimate_total_pop, na.rm = T)) %>%
  mutate(percent_pop = 100*(pop_served/etx_pop$total_pop),
         flag = "East TX")

# investigating whether east TX source breakdown is similar: 
pop_source_plot <- demo$census %>%
  filter(east_tx_flag == "yes")
ggplot(pop_source_plot, aes(x = primary_source_code, 
                            y = estimate_total_pop, 
                            color = primary_source_code)) + 
  geom_jitter() + 
  geom_jitter(data = pop_source_plot %>% filter(east_tx_flag == "yes"), 
             color = "pink") + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  labs(x = "",  y = "Estimated Population Served")

# creating a viz to go along with this: 
all_source <- rbind(pop_source_tx, pop_source_etx) %>%
  mutate(primary_source_code = as.factor(primary_source_code))

levels(all_source$primary_source_code) <- c("Groundwater, UI", "Groundwater",
                                            "Groundwater, Purchased", 
                                            "Surface Water", 
                                            "Surface Water, Purchased")

ggplot(all_source, aes(x = primary_source_code, y = total_sabs, 
                          fill = flag)) + 
  ggchicklet::geom_chicklet(stat = "identity", alpha = 0.5) + 
  scale_fill_discrete(name = "") + 
  theme_minimal() + 
  labs(x = "Primary Water Source", y = "Total Service Areas") + 
  coord_flip()

###############################################################################
# investigating ground water: 
###############################################################################
# NOTE: hatched aquifer sare subcrop areas (part of an aquifer that lies or dips
# below other formations)
gw_keys <- keys$well_gw_county
county_gw <- gw_keys %>%
  group_by(county_name) %>%
  distinct(aquifer_one, aquifer_two, aquifer_three, 
           aquifer_four, aquifer_five) %>%
  mutate(county_name = toupper(county_name)) %>%
  pivot_longer(aquifer_one:aquifer_five) %>%
  group_by(county_name) %>%
  distinct(value) %>%
  filter(!is.na(value)) 

# matching pwsid with county and then aquifer 
pwsid_gw <- water_source %>%
  filter(primary_source_code == "GW") %>%
  left_join(county_gw, c("county_served" = "county_name")) 

pwsid_summary <- pwsid_gw %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(value) %>%
  summarize(number_of_pwsids = length(unique(pwsid)))

pwsid_summary <- pwsid_summary[order(pwsid_summary$number_of_pwsids, decreasing = T),]

# finding the most common aquifers used in TX and East TX: 
ggplot(pwsid_summary, 
       aes(x = reorder(value, -number_of_pwsids), y = number_of_pwsids, 
                          color = value, fill = value)) + 
  geom_bar(stat = "identity") + 
  coord_flip() + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  labs(y = "Number of Utilities", x = "Aquifer")

etx_pwsid_summary <- pwsid_gw %>%  
  as.data.frame() %>%
  select(-geometry) %>%
  left_join(keys$analysis_keys) %>%
  filter(east_tx_flag == "yes") %>%
  group_by(value) %>%
  summarize(number_of_pwsids = length(unique(pwsid)))

ggplot(etx_pwsid_summary, 
       aes(x = reorder(value, -number_of_pwsids), y = number_of_pwsids, 
                          color = value, fill = value)) + 
  geom_bar(stat = "identity") + 
  coord_flip() + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  labs(y = "Number of Utilities", x = "Aquifer")


###############################################################################
# investigating surface water: 
###############################################################################
sw_intake_keys <- keys$pwsid_sw
pwsid_sw <- water_source %>%
  filter(primary_source_code == "SW") %>%
  left_join(sw_intake_keys) 

etx_pwsid_sw <- etx_source %>%
  filter(primary_source_code == "SW")

# how many do we have? 
pwsid_sw %>%
  as.data.frame() %>% 
  select(-geometry) %>%
  group_by(pwsid) %>%
  distinct(pwsid)
# 286 in all of TX

pwsid_sw %>%
  as.data.frame() %>% 
  select(-geometry) %>%
  filter(alt_res_name != "no matching wtrbdy") %>%
  group_by(pwsid) %>%
  nrow()
# we have matching reservoirs for 222 

# checking out east TX stats: 
etx_source %>%
  as.data.frame() %>% 
  filter(primary_source_code == "SW") %>%
  left_join(sw_intake_keys)  %>%
  select(-geometry) %>%
  filter(alt_res_name != "no matching wtrbdy") %>%
  distinct(pwsid)


# checking out impaired basins: 
imp_basin <- enviro_sw$impaired_basins
simp_basin_names <- unlist(str_split(imp_basin$basin_name, " River|Coastal|Creek"))
imp_basin$imp_basin_names <- simp_basin_names[seq(1, length(simp_basin_names), by = 2)] 

simple_basin_info <- imp_basin %>%
  select(imp_basin_names, pct_impaired)

pwsid_sw_basins <- merge(pwsid_sw, simple_basin_info, 
                         by.x = "basin_name_short", 
                         by.y = "imp_basin_names", all.x = TRUE)

# which reservoirs match to a bunch of pwsids?
by_res <- pwsid_sw_basins %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(res_name) %>%
  summarize(total = length(unique(pwsid)))

# reservoir matches in East TX
etx_by_res <- etx_pwsid_sw %>%
  as.data.frame() %>%
  select(-geometry) %>%
  left_join(keys$pwsid_sw) %>%
  group_by(res_name) %>%
  summarize(total = length(unique(pwsid)))

# narrowing in on East TX: 
etx_pwsids <- demo$census %>%
  filter(east_tx_flag == "yes") %>%
  distinct() %>%
  select(pwsid) %>%
  as.data.frame() %>%
  select(-geometry)

etx_pwsid_intakes <- keys$pwsid_sw %>%
  filter(pwsid %in% etx_pwsids$pwsid)

etx_pwsid_sw_basins <- merge(etx_pwsid_intakes, simple_basin_info, 
                         by.x = "basin_name_short", 
                         by.y = "imp_basin_names", all.x = TRUE)

# how many of these are pulling water from the Neches or Neches-Trinity, which 
# are both basins that are >60% impaired?
etx_pwsid_intakes %>%
  filter(basin_name_short %in% c("Neches", "Neches-Trinity")) %>%
  summarize(total_pwsids = length(unique(pwsid))) 
# 17 pwsids 

# do these utilities have more health-based violations?
sw_imp_basins <- etx_pwsid_intakes %>%
  # filter(basin_name_short %in% c("Neches", "Neches-Trinity")) %>%
  left_join(analysis_keys) %>%
  st_as_sf() %>%
  st_transform('+proj=longlat +datum=WGS84') %>%
  mutate(violation_flag = (healthbased_violations_5yr>0))

sw_imp_basins %>%
  filter(healthbased_violations_5yr > 0) %>%
  summarize(total = length(unique(pwsid)))
# 11 of them have had a health-based violation over the past 5 years (64.71%)

# basin boundaries: 
basins <- enviro_sw$major_river_basins %>%
  st_transform('+proj=longlat +datum=WGS84') %>%
  filter(basin_name %in% sw_imp_basins$basin_name_short)

# fixing where names didn't match: 
imp_basin_pct <- imp_basin %>%
  select(imp_basin_names, pct_impaired)
basins_pct <- merge(basins, imp_basin_pct, 
                by.x = "basin_name", 
                by.y = "imp_basin_names", all.x = T) %>%
  mutate(pct_impaired.y = 
         case_when(basin_name == "Cypress" ~ 49.41870, 
                   basin_name == "Neches-Trinity" ~ 67.12968, 
                   TRUE ~ pct_impaired.y)) %>%
  mutate(pct_impaired.y = round(basins_pct$pct_impaired.y, 1))

# mapping these: 
basin_pal <- colorFactor(
  palette = c("black", "red"),
  domain = etx_pwsid_sw_basins$violation_flag)

real_basin <- colorFactor(
  palette = viridis::inferno(6),
  domain = basins_pct$pct_impaired.y)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels, group = "Toner Lite") %>%
  addPolygons(data = basins_pct,
              opacity = 0.1,
              # stroke = TRUE,
              # color = "black",
              color = ~real_basin(pct_impaired.y),
              weight = 1, 
              label = paste0("% imp: ", basins_pct$pct_impaired.y)) %>%
  addPolygons(data = sw_imp_basins,
              opacity = 0.8,
              # stroke = TRUE,
              # color = "black",
              color = ~basin_pal(violation_flag),
              weight = 1,
              label = paste0("pwsid: ", sw_imp_basins$pwsid,
                "; viols: ", sw_imp_basins$violation_flag)) %>%
  addLegend("bottomright",
            pal = basin_pal,
            values = sw_imp_basins$violation_flag,
            title = "Health-based violations (5yr)",
            opacity = 1) %>%
  addLegend("bottomright",
            pal = real_basin,
            values = basins_pct$pct_impaired.y,
            title = "% Impaired", 
            opacity = 1) 


# Overall findings: 
# - most pwsids are geting water from aquifers, followed by purchasing 
#   surface water. 
# - of the pwsids pulling groundwater, most are pulling from the gulf coast 
#   major aquifer, followed by the trinity and carrizo major aquifers. 
# 
# - we have surface water intake information from 286 pwsids out of 392 
#   that pull surface water 
# - 53 pwsids are pulling surface water from a basin that is >= 60% 
#   impaired 
# - 15 pwsids are pulling from Lake Travis, and 12 from the Cedar Creek 
#   reservoir, and 12 from Lake Tawakoni 

```

## Investigating relationship of sw intakes to violations: 
```{r}
# surface water intake violations?
# curious about the monitoring, source water (GWR) violation
# SDWIS violations: 
viols <- wds$sdwis
# codes from SDWIS: 
sdwis_codes <- aws.s3::s3read_using(read.csv, 
                            object = "s3://tech-team-data/state-drinking-water/TX/raw/SDWA_REF_CODE_VALUES.csv") %>%
  janitor::clean_names()

# grabbing just violation codes & merging: 
violation_codes <- sdwis_codes %>%
  filter(value_type == "VIOLATION_CODE")

viol_type <- merge(viols, violation_codes, 
                   by.x = "violation_code", 
                   by.y = "value_code")

cont_codes <- sdwis_codes %>%
  filter(value_type == "CONTAMINANT_CODE") %>%
  rename(cont_code = value_code, 
         cont_type = value_type, 
         cont_desc = value_description)

cont_viol_type <- merge(viol_type, cont_codes, 
                        by.x = "contaminant_code", 
                        by.y = "cont_code")

# taking a closer look at source water violations
sw_viols <- cont_viol_type %>%
  filter(str_detect(value_description, "Source Water")) 

# what are the characteristics of these utilities? 
sab_info <- demo$census %>% 
  select(pwsid, pws_name, primacy_agency_code, primacy_type, 
         primary_source_code) %>%
  as.data.frame() %>%
  select(-geometry)

sw_viol_char <- keys$analysis_keys %>%
  filter(pwsid %in% sw_viols$pwsid) %>% 
  left_join(sab_info) %>%
  filter(east_tx_flag == "yes") %>% 
  st_transform('+proj=longlat +datum=WGS84')
mean(sw_viol_char$healthbased_violations_5yr)

# where are they located? 
cvi_pal <- colorNumeric(
  palette = viridis::mako(9),
  domain = sw_viol_char$healthbased_violations_5yr)

leaflet() %>%
  addProviderTiles(providers$CartoDB.VoyagerNoLabels, group = "Toner Lite") %>%
  addPolygons(data = sw_viol_char,
              fillOpacity = 0.9,
              stroke = TRUE,
              color = "black",
              fillColor = ~cvi_pal(healthbased_violations_5yr),
              weight = 1,
              label = paste0("pwsid: ", sw_viol_char$pwsid,
                "; hbv: ", 
                round(sw_viol_char$healthbased_violations_5yr, 2), 
                "; water source: ", sw_viol_char$primary_source_code)) %>%
  addLegend("bottomright",
            pal = cvi_pal,
            values = sw_viol_char$healthbased_violations_5yr,
            title = "health-based viols",
            opacity = 1)

# most of these are pulling groundwater and there's no discernible pattern 
# what about sw_intakes? 
sw_intakes <- keys$pwsid_sw %>%
  left_join(keys$analysis_keys) %>%
  filter(east_tx_flag == "yes")

test <- merge(sw_intakes, sw_viols, by = "pwsid")

# any trends by reservoir?
res_summary <- sw_intakes %>%
  group_by(res_name) %>%
  summarize(total = length(unique(pwsid)), 
            mean_5yr_hbv = mean(healthbased_violations_5yr))
# not really - sample size too small 
```



